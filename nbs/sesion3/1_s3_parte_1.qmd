---
format: html
toc: false
---

## Parte 1 ‚Äì Un problema de predicci√≥n m√°s avanzado: detecci√≥n de objetos

En esta primera parte de la sesi√≥n se analiza una funcionalidad de software que aborda un **problema de predicci√≥n m√°s avanzado** que los trabajados en sesiones anteriores, pero que mantiene una estructura conceptual similar.

El objetivo no es aprender una nueva t√©cnica, sino **entender c√≥mo cambia el problema de predicci√≥n** y c√≥mo ese cambio impacta en el comportamiento de la aplicaci√≥n.

---

## Continuidad con lo ya visto

En la Sesi√≥n 2 se trabaj√≥ con funcionalidades de **clasificaci√≥n de im√°genes**, donde el sistema recibe una entrada (imagen o video) y produce una **√∫nica etiqueta** como resultado.

Desde el punto de vista del software, ese tipo de funcionalidad responde a una pregunta simple del tipo:

‚Äú¬øQu√© es esta imagen?‚Äù

La detecci√≥n de objetos mantiene la misma idea general de predicci√≥n, pero **extiende el problema**.

---

## Ejemplo del caso m√°s avanzado

üëâ [Ejemplo de detecci√≥n de objetos](https://dci-courses.github.io/bootcamp-dci/ml5/object_detection.html)

Este ejemplo muestra una funcionalidad que utiliza un modelo preentrenado para **detectar m√∫ltiples objetos simult√°neamente** en una imagen o en un flujo de video, marcando su posici√≥n aproximada en pantalla.

El comportamiento observable de la aplicaci√≥n permite analizar c√≥mo cambia la predicci√≥n cuando la salida del modelo deja de ser una etiqueta √∫nica.

---

## C√≥mo cambia el problema de predicci√≥n

En una funcionalidad de detecci√≥n de objetos, el sistema ya no produce una sola predicci√≥n, sino **m√∫ltiples predicciones simult√°neas**.

El problema deja de ser identificar una imagen completa y pasa a ser:

- identificar qu√© objetos aparecen,
- determinar cu√°ntos objetos hay,
- y estimar d√≥nde se encuentra cada uno dentro de la imagen o el video.

Esto implica que la salida del modelo ya no es una etiqueta simple, sino un **conjunto de resultados estructurados**.

---

## Tipo de entrada y tipo de salida

Desde el punto de vista de la aplicaci√≥n:

- la **entrada** puede ser una imagen fija o un flujo de video,
- la **salida** es una colecci√≥n de detecciones.

Cada detecci√≥n incluye informaci√≥n distinta a la vista en la clasificaci√≥n simple, como:
- una etiqueta asociada al objeto,
- y una ubicaci√≥n aproximada dentro del espacio visual.

La aplicaci√≥n debe interpretar esta informaci√≥n y decidir c√≥mo representarla en la interfaz.

---

## Implicancias para el dise√±o del software

Este cambio en el problema de predicci√≥n tiene consecuencias directas en el dise√±o de la funcionalidad:

- la interfaz ya no muestra un √∫nico resultado,
- el sistema debe manejar m√∫ltiples predicciones al mismo tiempo,
- el comportamiento del sistema es din√°mico y cambia continuamente,
- y la aplicaci√≥n debe actualizar su estado en funci√≥n de nuevas predicciones.

Estas decisiones no dependen del modelo en s√≠, sino de **c√≥mo la aplicaci√≥n utiliza las predicciones**.

---

## En qu√© fijarse durante el an√°lisis

Al analizar este caso m√°s avanzado, el foco est√° en observar:

- c√≥mo se diferencia este problema de una clasificaci√≥n simple,
- qu√© tipo de informaci√≥n entrega el modelo,
- c√≥mo esa informaci√≥n es utilizada por la aplicaci√≥n,
- y qu√© nuevas decisiones de dise√±o aparecen.

El inter√©s est√° en **comprender el problema de predicci√≥n**, no en evaluar la calidad del modelo ni la precisi√≥n de las detecciones.

---

::: {.callout-note}
Este caso sirve como marco de referencia para las demostraciones de la segunda parte de la sesi√≥n, mostrando que distintas funcionalidades de IA pueden compartir herramientas similares, pero resolver **problemas de predicci√≥n distintos**.
:::
