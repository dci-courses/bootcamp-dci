[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "bootcamp-dci",
    "section": "",
    "text": "üëã Bienvenido\n\nü§ñüíª Bootcamp de Implementaci√≥n de Funcionalidades de Software basadas en Inteligencia Artificial\nEn este bootcamp aprender√°s a implementar funcionalidades de software que se basan en inteligencia artificial, integr√°ndolas en aplicaciones reales. El foco est√° en construir funcionalidades concretas, no en entrenar modelos ni en estudiar teor√≠a de inteligencia artificial.\nTrabajar√°s con ml5.js ü§ñ (https://ml5js.org), una biblioteca de aprendizaje autom√°tico orientada al desarrollo de aplicaciones interactivas, y con p5.js üé® (https://p5js.org), una biblioteca para programaci√≥n creativa que facilita la creaci√≥n de interfaces visuales e interactivas en el navegador. A lo largo del bootcamp analizar√°s e implementar√°s una funcionalidad de clasificaci√≥n de im√°genes üñºÔ∏è, abordando su integraci√≥n, comportamiento y validaci√≥n dentro de una aplicaci√≥n de software.\nEl material est√° organizado para que:\n\nComprendas primero c√≥mo funciona una funcionalidad basada en IA\n\nLa implementes paso a paso\n\nLa expliques y demuestres al final del bootcamp\n\n\n\n\n\nüéØ ¬øQu√© puedes esperar de este bootcamp?\nEn este bootcamp aprender√°s a:\n\nComprender c√≥mo una funcionalidad basada en IA se integra dentro de un sistema de software\n\nImplementar una funcionalidad de clasificaci√≥n de im√°genes utilizando ml5.js ü§ñ junto con p5.js üé®\n\nAnalizar entradas, salidas, flujo de datos y decisiones de dise√±o asociadas a funcionalidades con IA\n\nExplicar y demostrar el funcionamiento de una funcionalidad implementada por ti\n\nComunicar decisiones t√©cnicas de forma clara y precisa\n\nEl objetivo es que, al finalizar la tercera sesi√≥n, cuentes con una peque√±a implementaci√≥n funcional, construida de manera progresiva a lo largo del bootcamp.\n\n\n\nüñ•Ô∏è Sesiones sincr√≥nicas\nLas tres sesiones sincr√≥nicas online se realizar√°n a trav√©s de Zoom, utilizando el mismo enlace para todas las sesiones.\n\n‚è∞ Horario: 17:00 a 18:00 (hora de Chile)\n\nüîó Zoom: https://reuna.zoom.us/j/87367765384\n\nAntes de cada sesi√≥n sincr√≥nica, se espera que los estudiantes:\n\nRevisen el material previo indicado\n\nEjecuten los ejemplos base\n\nLleguen con dudas o avances concretos\n\n\n\n\nüìÖ ¬øCu√°l es el programa del bootcamp?\n\n\n\n\n\n\n\n\nSesi√≥n y fecha\nTema\nDescripci√≥n\n\n\n\n\nSesi√≥n 1 ‚Äì Martes 6 de enero de 2026\nComprender una funcionalidad de clasificaci√≥n de im√°genes ü§ñ\nAn√°lisis guiado de una funcionalidad de software que incorpora IA. Se estudia su prop√≥sito, flujo de datos, entradas, salidas y comportamiento esperado.\n\n\nSesi√≥n 2 ‚Äì Mi√©rcoles 7 de enero de 2026\nImplementaci√≥n de clasificaci√≥n de im√°genes üñºÔ∏è\nImplementaci√≥n pr√°ctica de una funcionalidad de clasificaci√≥n de im√°genes utilizando ml5.js ü§ñ y p5.js üé®, integr√°ndola en una aplicaci√≥n de software.\n\n\nSesi√≥n 3 ‚Äì Jueves 8 de enero de 2026\nDemostraciones de los estudiantes üé§\nPresentaci√≥n y explicaci√≥n de una peque√±a implementaci√≥n funcional, desarrollada a partir del trabajo realizado durante el bootcamp.\n\n\n\n\n\n\nüß© ¬øCu√°les son los prerrequisitos?\nPara seguir este bootcamp se espera que tengas:\n\nConocimientos b√°sicos de programaci√≥n\n\nFamiliaridad general con desarrollo de software\n\nExperiencia b√°sica en JavaScript o desarrollo web (recomendado, no excluyente)\n\nNo se asume conocimiento previo de aprendizaje autom√°tico ni de las bibliotecas utilizadas.\n\n\n\nüõ†Ô∏è ¬øQu√© herramientas necesito?\nSolo necesitas:\n\nUn computador con conexi√≥n a internet\n\nUn navegador web moderno\n\nUn editor de c√≥digo (Visual Studio Code)\n\n\n\n\nüöÄ ¬øC√≥mo aprovechar mejor el bootcamp?\nPara sacar el m√°ximo provecho:\n\nRevisa el material antes de cada sesi√≥n sincr√≥nica\n\nEjecuta y modifica los ejemplos propuestos\n\nPrueba variaciones en la funcionalidad que est√°s construyendo\n\nPrepara tu demostraci√≥n explicando:\n\nqu√© hace la funcionalidad\n\nc√≥mo est√° implementada\n\nqu√© decisiones t√©cnicas tomaste\n\n\n\n\n\nüîó Continuidad del programa de bootcamps\nEste es el primero de una serie de bootcamps. Los siguientes estar√°n orientados espec√≠ficamente a:\n\nLLMs, agentes y su integraci√≥n en aplicaciones de software\n\nMCP y arquitecturas de interacci√≥n con modelos\n\nM√©todos y criterios para evaluar sistemas basados en LLMs\n\nEste bootcamp cumple, por tanto, un rol formativo clave: preparar el terreno conceptual y pr√°ctico para abordar estas tecnolog√≠as con criterio t√©cnico y no solo desde el uso superficial de herramientas.\n\n\n\nüìù Inscripciones tard√≠as (cupos adicionales)\nDebido al inter√©s generado por el bootcamp, hemos recibido varios mensajes solicitando cupos adicionales. Por este motivo, y de manera excepcional, estamos aceptando nuevas inscripciones tard√≠as, siempre que existan cupos disponibles.\nSi no alcanzaste a inscribirte en el per√≠odo inicial, puedes hacerlo directamente a trav√©s del siguiente formulario:\nüëâ Formulario de inscripci√≥n:\nCompletar formulario de inscripci√≥n\nLas inscripciones se cerrar√°n autom√°ticamente una vez completados los cupos adicionales.\n\n\n\nüí∞ Financiamiento\nEste bootcamp cuenta con financiamiento del Proyecto ANID Ingenier√≠a de Frontera hacia el 2030 y del Fondo de Desarrollo Educativo UFRO, como una experiencia piloto orientada al fortalecimiento de competencias t√©cnicas en la articulaci√≥n pregrado‚Äìposgrado.",
    "crumbs": [
      "üëã Bienvenido"
    ]
  },
  {
    "objectID": "association-rules/00_ejemplo_1.1.html",
    "href": "association-rules/00_ejemplo_1.1.html",
    "title": "Introducci√≥n a las Reglas de Asociaci√≥n",
    "section": "",
    "text": "Las reglas de asociaci√≥n son una t√©cnica de miner√≠a de datos que permite descubrir relaciones interesantes entre variables en grandes conjuntos de datos. Estas reglas son especialmente √∫tiles en el an√°lisis de datos de transacciones, como los registros de ventas en un supermercado. Vamos a crear un ejemplo did√°ctico para entender c√≥mo funcionan.\n\n\nDefiniciones\n√çtem (Item): Un √≠tem es un producto o art√≠culo individual que se vende en una transacci√≥n. En el contexto de las reglas de asociaci√≥n, un conjunto de √≠tems se refiere a uno o m√°s productos que se compran juntos en una transacci√≥n.\n\nSoporte (Support): Es la proporci√≥n de transacciones que contienen un conjunto de √≠tems espec√≠fico. Ayuda a identificar cu√°n com√∫n es un conjunto de √≠tems en el conjunto de datos.\n\\[\n\\text{Soporte} = \\frac{\\text{N√∫mero de transacciones que contienen el conjunto de √≠tems}}{\\text{N√∫mero total de transacciones}}\n\\]\n\nExplicaci√≥n:\n\nEl soporte mide la frecuencia con la que un conjunto de √≠tems aparece en el conjunto de datos.\nEs √∫til porque nos ayuda a identificar cu√°les combinaciones de productos son comunes en nuestras transacciones.\nPor ejemplo, si el soporte de ‚Äúleche y pan‚Äù es alto, significa que estos productos se compran juntos con frecuencia.\n\n\nConfianza (Confidence): Es la proporci√≥n de transacciones que contienen el conjunto de √≠tems A que tambi√©n contienen el conjunto de √≠tems B. Indica la probabilidad de que B se compre cuando A se compra.\n\\[\n\\text{Confianza}(A \\rightarrow B) = \\frac{\\text{Soporte}(A \\cup B)}{\\text{Soporte}(A)}\n\\]\n\nExplicaci√≥n:\n\nLa confianza mide la probabilidad de que el √≠tem B sea comprado cuando el √≠tem A ya ha sido comprado.\nEs √∫til para entender la fuerza de la regla de asociaci√≥n.\nPor ejemplo, una confianza del 75% para la regla ‚Äúleche \\(\\rightarrow\\) pan‚Äù significa que el 75% de las veces que los clientes compran leche, tambi√©n compran pan.\n\n\nLift: Mide la relaci√≥n entre la ocurrencia de A y B. Indica cu√°nto m√°s probable es que B se compre cuando A se compra, en comparaci√≥n con la probabilidad de comprar B sin A.\n\\[\n\\text{Lift}(A \\rightarrow B) = \\frac{\\text{Confianza}(A \\rightarrow B)}{\\text{Soporte}(B)}\n\\]\n\nExplicaci√≥n:\n\nEl lift mide la relaci√≥n entre la ocurrencia de A y B en comparaci√≥n con su ocurrencia esperada si fueran independientes.\nUn lift mayor a 1 indica que A y B ocurren juntos m√°s a menudo de lo esperado si fueran independientes.\nEs √∫til para identificar relaciones significativas entre productos.\nPor ejemplo, si el lift de ‚Äúleche \\(\\rightarrow\\) pan‚Äù es 1.125, significa que los clientes que compran leche son 1.125 veces m√°s propensos a comprar pan que el promedio de todos los clientes.\n\n\n\n\n\nEjemplo\n\nImaginemos que gestionas un peque√±o supermercado y tienes los datos de las transacciones de los √∫ltimos meses.\nQuieres analizar estos datos para descubrir patrones en las compras de tus clientes, es decir, qu√© productos suelen comprarse juntos.\n\n\n\nDatos\nSupongamos que tenemos las siguientes transacciones:\n\nTransacci√≥n 1: Leche, Pan, Mantequilla\nTransacci√≥n 2: Leche, Pan\nTransacci√≥n 3: Leche, Manzana\nTransacci√≥n 4: Pan, Mantequilla\nTransacci√≥n 5: Leche, Pan, Mantequilla, Manzana\nTransacci√≥n 6: Manzana, Mantequilla\n\n\nPaso 1: Crear la Matriz de Transacciones\n\nPrimero, representamos las transacciones en una matriz donde cada fila representa una transacci√≥n y cada columna representa un producto.\nUsamos 1 para indicar que un producto se compr√≥ en esa transacci√≥n y 0 en caso contrario.\n\n\n\n\n\nLeche\nPan\nMantequilla\nManzana\n\n\n\n\nT1\n1\n1\n1\n0\n\n\nT2\n1\n1\n0\n0\n\n\nT3\n1\n0\n0\n1\n\n\nT4\n0\n1\n1\n0\n\n\nT5\n1\n1\n1\n1\n\n\nT6\n0\n0\n1\n1\n\n\n\n\n\nPaso 2: Identificar Patrones Frecuentes\n\nPara identificar patrones frecuentes, calculamos el soporte de cada combinaci√≥n de productos.\nEl soporte es la proporci√≥n de transacciones en las que aparece una combinaci√≥n de productos.\n\nSoporte:\n\nSoporte de \\(\\{Leche\\}\\) = 4/6\nSoporte de \\(\\{Pan\\}\\) = 4/6\nSoporte de \\(\\{Mantequilla\\}\\) = 4/6\nSoporte de \\(\\{Manzana\\}\\) = 3/6\nSoporte de \\(\\{Leche, Pan\\}\\) = 3/6\nSoporte de \\(\\{Leche, Mantequilla\\}\\) = 2/6\nSoporte de \\(\\{Pan, Mantequilla\\}\\) = 3/6\nSoporte de \\(\\{Leche, Manzana\\}\\) = 2/6\nSoporte de \\(\\{Pan, Manzana\\}\\) = 1/6\nSoporte de \\(\\{Mantequilla, Manzana\\}\\) = 2/6\n\n\n\nPaso 3: Generar Reglas de Asociaci√≥n\n\nUna vez identificados los patrones frecuentes, generamos reglas de asociaci√≥n.\nEstas reglas tienen la forma \\(A \\rightarrow B\\), donde A (antecedente) y B (consecuente) son conjuntos de productos.\nPara cada regla, calculamos la confianza y el lift.\nUna vez identificados los patrones frecuentes, generamos reglas de asociaci√≥n.\n\nReglas:\n\nRegla: \\(\\{Leche\\} -&gt; \\{Pan\\}\\)\n\n\\[Confianza = \\frac{\\text{Soporte}(\\{Leche, Pan\\})}{\\text{Soporte}(\\{Leche\\})} = \\frac{3/6}{4/6} = 0.75\\]\n\\[Lift = \\frac{\\text{Confianza}}{\\text{Soporte}(\\{Pan\\})} = \\frac{0.75}{4/6} = 1.125\\]\n\nRegla: {Pan} -&gt; {Leche}\n\n\\[Confianza = \\frac{\\text{Soporte}(\\{Leche, Pan\\})}{\\text{Soporte}(\\{Pan\\})} = \\frac{3/6}{4/6} = 0.75\\]\n\\[Lift = \\frac{\\text{Confianza}}{\\text{Soporte}(\\{Leche\\})} = \\frac{0.75}{4/6} = 1.125\\]\n\n\n\n\nPaso 4: Interpretaci√≥n\n\nLa regla \\(\\{Leche\\} \\rightarrow \\{Pan\\}\\) con una confianza de 0.75 significa que el 75% de las veces que los clientes compran leche, tambi√©n compran pan.\nUn lift de 1.125 indica una leve relaci√≥n positiva entre la compra de leche y pan, sugiriendo que comprar leche aumenta la probabilidad de que tambi√©n se compre pan.\n\n\nimport pandas as pd\n\n# Crear el dataframe con las transacciones\ndata = {\n    'Leche': [1, 1, 1, 0, 1, 0],\n    'Pan': [1, 1, 0, 1, 1, 0],\n    'Mantequilla': [1, 0, 0, 1, 1, 1],\n    'Manzana': [0, 0, 1, 0, 1, 1]\n}\n\ndf = pd.DataFrame(data, index=['T1', 'T2', 'T3', 'T4', 'T5', 'T6'])\nprint(df)\n\n    Leche  Pan  Mantequilla  Manzana\nT1      1    1            1        0\nT2      1    1            0        0\nT3      1    0            0        1\nT4      0    1            1        0\nT5      1    1            1        1\nT6      0    0            1        1\n\n\n\nimport gradio as gr\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Funci√≥n de prueba que hace predicciones seg√∫n par√°metros\ndef hacer_predicciones(param1: float, param2: int, texto: str):\n    # Retorna una tabla de resultados + una gr√°fica\n    df = pd.DataFrame({\n        \"entrada\": [texto],\n        \"predicci√≥n\": [\"clase A\"], \n        \"probabilidad\": [0.82]\n    })\n    fig, ax = plt.subplots()\n    ax.bar([\"clase A\", \"clase B\"], [0.82, 0.18])\n    ax.set_ylabel(\"Probabilidad\")\n    return df, fig\n\n# Interfaz Gradio\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Experimento interactivo del cap√≠tulo de Predicciones\")\n    param1 = gr.Slider(0.0, 1.0, value=0.5, label=\"Par√°metro 1\")\n    param2 = gr.Slider(1, 10, value=3, label=\"Par√°metro 2\")\n    texto = gr.Textbox(lines=3, label=\"Texto de entrada\")\n    boton = gr.Button(\"Predecir\")\n\n    tabla = gr.Dataframe(headers=[\"entrada\", \"predicci√≥n\", \"probabilidad\"])\n    graf = gr.Plot()\n\n    boton.click(fn=hacer_predicciones, inputs=[param1, param2, texto], outputs=[tabla, graf])\n\n    # Algunos ejemplos extra√≠dos del libro\n    demos = [\n        [0.5, 3, \"Texto de ejemplo\"],\n        [0.8, 5, \"Otro ejemplo\"]\n    ]\n    gr.Examples(demos, inputs=[param1, param2, texto])\n    \ndemo.launch(share=True)\n\n/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://89488052ca5b3d5447.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)"
  },
  {
    "objectID": "sesion3/2_s3_parte_2.html",
    "href": "sesion3/2_s3_parte_2.html",
    "title": "bootcamp-dci",
    "section": "",
    "text": "En esta segunda parte de la sesi√≥n, los estudiantes realizan una demostraci√≥n de una funcionalidad de software basada en inteligencia artificial, desarrollada a partir del trabajo realizado durante el bootcamp.\nEl objetivo principal es explicar el funcionamiento de la funcionalidad, poniendo el foco en el problema de predicci√≥n que aborda y en c√≥mo la aplicaci√≥n utiliza las predicciones generadas por el modelo.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 2 ‚Äì Demostraci√≥n y explicaci√≥n de una funcionalidad"
    ]
  },
  {
    "objectID": "sesion3/2_s3_parte_2.html#parte-2-demostraci√≥n-y-explicaci√≥n-de-una-funcionalidad",
    "href": "sesion3/2_s3_parte_2.html#parte-2-demostraci√≥n-y-explicaci√≥n-de-una-funcionalidad",
    "title": "bootcamp-dci",
    "section": "",
    "text": "En esta segunda parte de la sesi√≥n, los estudiantes realizan una demostraci√≥n de una funcionalidad de software basada en inteligencia artificial, desarrollada a partir del trabajo realizado durante el bootcamp.\nEl objetivo principal es explicar el funcionamiento de la funcionalidad, poniendo el foco en el problema de predicci√≥n que aborda y en c√≥mo la aplicaci√≥n utiliza las predicciones generadas por el modelo.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 2 ‚Äì Demostraci√≥n y explicaci√≥n de una funcionalidad"
    ]
  },
  {
    "objectID": "sesion3/2_s3_parte_2.html#qu√©-se-espera-en-la-demostraci√≥n",
    "href": "sesion3/2_s3_parte_2.html#qu√©-se-espera-en-la-demostraci√≥n",
    "title": "bootcamp-dci",
    "section": "Qu√© se espera en la demostraci√≥n",
    "text": "Qu√© se espera en la demostraci√≥n\nDurante la demostraci√≥n, cada estudiante o grupo debe presentar una funcionalidad que:\n\nprocese una entrada clara (imagen o video),\nintegre un modelo de inteligencia artificial,\ny produzca una salida observable para el usuario.\n\nLa demostraci√≥n debe permitir visualizar el comportamiento del sistema y entender c√≥mo responde frente a distintas entradas.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 2 ‚Äì Demostraci√≥n y explicaci√≥n de una funcionalidad"
    ]
  },
  {
    "objectID": "sesion3/2_s3_parte_2.html#qu√©-deben-explicar",
    "href": "sesion3/2_s3_parte_2.html#qu√©-deben-explicar",
    "title": "bootcamp-dci",
    "section": "Qu√© deben explicar",
    "text": "Qu√© deben explicar\nM√°s all√° de mostrar que la funcionalidad ‚Äúfunciona‚Äù, los estudiantes deben ser capaces de explicar:\n\nqu√© tipo de problema de predicci√≥n resuelve la funcionalidad,\nqu√© informaci√≥n entrega el modelo como resultado,\nc√≥mo la aplicaci√≥n interpreta y utiliza esa informaci√≥n,\ny c√≥mo estas decisiones influyen en el comportamiento del sistema.\n\nNo se espera una explicaci√≥n t√©cnica detallada del modelo ni de la librer√≠a utilizada.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 2 ‚Äì Demostraci√≥n y explicaci√≥n de una funcionalidad"
    ]
  },
  {
    "objectID": "sesion3/2_s3_parte_2.html#relaci√≥n-con-el-caso-m√°s-avanzado",
    "href": "sesion3/2_s3_parte_2.html#relaci√≥n-con-el-caso-m√°s-avanzado",
    "title": "bootcamp-dci",
    "section": "Relaci√≥n con el caso m√°s avanzado",
    "text": "Relaci√≥n con el caso m√°s avanzado\nLa demostraci√≥n se realiza a la luz del an√°lisis del caso m√°s avanzado visto en la primera parte de la sesi√≥n.\nEsto permite que los estudiantes establezcan comparaciones, por ejemplo:\n\nentre una predicci√≥n √∫nica y m√∫ltiples predicciones,\nentre una salida simple y una salida estructurada,\nentre un comportamiento est√°tico y uno din√°mico.\n\nEl √©nfasis est√° en reconocer similitudes y diferencias en el tipo de problema de predicci√≥n, no en replicar el caso avanzado.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 2 ‚Äì Demostraci√≥n y explicaci√≥n de una funcionalidad"
    ]
  },
  {
    "objectID": "sesion3/2_s3_parte_2.html#criterio-central-de-evaluaci√≥n",
    "href": "sesion3/2_s3_parte_2.html#criterio-central-de-evaluaci√≥n",
    "title": "bootcamp-dci",
    "section": "Criterio central de evaluaci√≥n",
    "text": "Criterio central de evaluaci√≥n\nLa evaluaci√≥n de esta parte se basa en un criterio central:\n\nla claridad y coherencia de la explicaci√≥n.\n\nNo se eval√∫a la precisi√≥n de la predicci√≥n, ni la complejidad del c√≥digo, ni la originalidad de la funcionalidad.\nLo relevante es que el estudiante pueda explicar correctamente qu√© est√° prediciendo el sistema y c√≥mo se usa esa predicci√≥n.\n\n\n\n\n\n\n\nTip\n\n\n\nUna buena demostraci√≥n no es la que ‚Äúacierta m√°s‚Äù, sino la que mejor explica el problema de predicci√≥n que la funcionalidad est√° resolviendo.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 2 ‚Äì Demostraci√≥n y explicaci√≥n de una funcionalidad"
    ]
  },
  {
    "objectID": "sesion3/0_s3_parte_0.html",
    "href": "sesion3/0_s3_parte_0.html",
    "title": "bootcamp-dci",
    "section": "",
    "text": "Esta sesi√≥n est√° dedicada a presentar y explicar funcionalidades de software basadas en inteligencia artificial, desarrolladas a partir del trabajo realizado durante el bootcamp.\nA diferencia de las sesiones anteriores, el foco no est√° en implementar nuevas funcionalidades, sino en explicar correctamente el problema de predicci√≥n que resuelve una aplicaci√≥n, c√≥mo se comporta y qu√© decisiones de dise√±o est√°n involucradas.",
    "crumbs": [
      "Sesi√≥n 3",
      "Sesi√≥n 3 ‚Äì Demostraciones de los estudiantes üé§"
    ]
  },
  {
    "objectID": "sesion3/0_s3_parte_0.html#sesi√≥n-3-demostraciones-de-los-estudiantes",
    "href": "sesion3/0_s3_parte_0.html#sesi√≥n-3-demostraciones-de-los-estudiantes",
    "title": "bootcamp-dci",
    "section": "",
    "text": "Esta sesi√≥n est√° dedicada a presentar y explicar funcionalidades de software basadas en inteligencia artificial, desarrolladas a partir del trabajo realizado durante el bootcamp.\nA diferencia de las sesiones anteriores, el foco no est√° en implementar nuevas funcionalidades, sino en explicar correctamente el problema de predicci√≥n que resuelve una aplicaci√≥n, c√≥mo se comporta y qu√© decisiones de dise√±o est√°n involucradas.",
    "crumbs": [
      "Sesi√≥n 3",
      "Sesi√≥n 3 ‚Äì Demostraciones de los estudiantes üé§"
    ]
  },
  {
    "objectID": "sesion3/0_s3_parte_0.html#estructura-de-la-sesi√≥n",
    "href": "sesion3/0_s3_parte_0.html#estructura-de-la-sesi√≥n",
    "title": "bootcamp-dci",
    "section": "Estructura de la sesi√≥n",
    "text": "Estructura de la sesi√≥n\nLa sesi√≥n se organiza en dos partes complementarias.\nEn la primera parte, se analiza un caso m√°s avanzado, conceptualmente similar a los ejemplos trabajados en sesiones anteriores, pero que aborda un problema de predicci√≥n distinto y m√°s complejo. Este an√°lisis permite ampliar la discusi√≥n y contrastar distintos tipos de predicciones dentro de una aplicaci√≥n de software.\nEn la segunda parte, los estudiantes realizan una demostraci√≥n de una funcionalidad funcional, mostrando su comportamiento y explicando c√≥mo utiliza un modelo de IA para producir predicciones.",
    "crumbs": [
      "Sesi√≥n 3",
      "Sesi√≥n 3 ‚Äì Demostraciones de los estudiantes üé§"
    ]
  },
  {
    "objectID": "sesion3/0_s3_parte_0.html#enfoque-de-la-sesi√≥n",
    "href": "sesion3/0_s3_parte_0.html#enfoque-de-la-sesi√≥n",
    "title": "bootcamp-dci",
    "section": "Enfoque de la sesi√≥n",
    "text": "Enfoque de la sesi√≥n\nDurante toda la sesi√≥n, la atenci√≥n est√° puesta en:\n\nidentificar qu√© problema de predicci√≥n resuelve la funcionalidad,\ncomprender el tipo de entrada y salida del sistema,\ny explicar c√≥mo la aplicaci√≥n utiliza las predicciones para construir su comportamiento.\n\nNo se eval√∫a la correcci√≥n de la predicci√≥n ni el rendimiento del modelo, sino la comprensi√≥n del problema y la capacidad de explicarlo con claridad.\n\n\n\n\n\n\n\nNota\n\n\n\nEsta sesi√≥n cierra el bootcamp conectando los conceptos trabajados previamente y reforzando la idea de que integrar inteligencia artificial en software implica, antes que nada, entender el problema de predicci√≥n que se est√° resolviendo.",
    "crumbs": [
      "Sesi√≥n 3",
      "Sesi√≥n 3 ‚Äì Demostraciones de los estudiantes üé§"
    ]
  },
  {
    "objectID": "ml5/hand_pose.html",
    "href": "ml5/hand_pose.html",
    "title": "Detecci√≥n de Pose de Manos",
    "section": "",
    "text": "Este modelo utiliza HandPose de ml5.js para identificar y rastrear 21 puntos clave en cada mano detectada. El modelo puede rastrear m√∫ltiples manos simult√°neamente y proporciona las coordenadas exactas de cada articulaci√≥n.\nInstrucciones:",
    "crumbs": [
      "Ejemplos",
      "Detecci√≥n de Pose de Manos"
    ]
  },
  {
    "objectID": "ml5/hand_pose.html#explicaci√≥n-del-c√≥digo",
    "href": "ml5/hand_pose.html#explicaci√≥n-del-c√≥digo",
    "title": "Detecci√≥n de Pose de Manos",
    "section": "Explicaci√≥n del C√≥digo",
    "text": "Explicaci√≥n del C√≥digo\n\nC√≥digo Completo\nlet handpose;\nlet video;\nlet predictions = [];\n\nfunction setup() {\n    createCanvas(640, 480);\n    \n    // Create the webcam video and hide it\n    video = createCapture(VIDEO);\n    video.size(640, 480);\n    video.hide();\n    \n    // Load the handpose model\n    handpose = ml5.handpose(video, modelReady);\n}\n\nfunction modelReady() {\n    console.log(\"Handpose Model Ready!\");\n    // Start detecting hands\n    handpose.on('predict', gotHands);\n}\n\n// Callback function for when handpose outputs data\nfunction gotHands(results) {\n    // Save the output to the predictions variable\n    predictions = results;\n}\n\nfunction draw() {\n    // Draw the webcam video\n    image(video, 0, 0, width, height);\n    \n    // Draw all the tracked hand points\n    for (let i = 0; i &lt; predictions.length; i++) {\n        let prediction = predictions[i];\n        for (let j = 0; j &lt; prediction.landmarks.length; j++) {\n            let keypoint = prediction.landmarks[j];\n            fill(0, 255, 0);\n            noStroke();\n            circle(keypoint[0], keypoint[1], 10);\n        }\n    }\n}\n\n\n1. Declaraci√≥n de Variables\nPrimero, declaramos las variables que necesitaremos:\nlet handpose;\nlet video;\nlet predictions = [];\n\nhandpose: Almacenar√° el modelo HandPose de ml5.js\nvideo: Contendr√° la captura de la c√°mara web\npredictions: Array que guardar√° todas las manos detectadas y sus puntos clave\n\n\n\n2. Configuraci√≥n Inicial (setup)\nLa funci√≥n setup() configura el canvas, la c√°mara y carga el modelo:\nfunction setup() {\n    createCanvas(640, 480);\n    video = createCapture(VIDEO);\n    video.size(640, 480);\n    video.hide();\n    handpose = ml5.handpose(video, modelReady);\n}\n\ncreateCanvas(640, 480): Crea un lienzo de 640x480 p√≠xeles\ncreateCapture(VIDEO): Captura el video de la webcam\nvideo.hide(): Oculta el elemento HTML del video (solo mostramos el canvas)\nml5.handpose(video, modelReady): Carga el modelo HandPose con el video como entrada\n\n\n\n3. Inicio de Detecci√≥n (modelReady)\nEsta funci√≥n se ejecuta cuando el modelo est√° listo:\nfunction modelReady() {\n    console.log(\"Handpose Model Ready!\");\n    handpose.on('predict', gotHands);\n}\n\nhandpose.on('predict', gotHands): Registra un listener para las predicciones\nCada vez que el modelo detecta manos, llama autom√°ticamente a gotHands()\nEste patr√≥n permite detecci√≥n continua en tiempo real\n\n\n\n4. Procesamiento de Resultados (gotHands)\nEsta funci√≥n recibe las predicciones del modelo:\nfunction gotHands(results) {\n    predictions = results;\n}\n\nresults: Array con todas las manos detectadas en el frame actual\nCada mano contiene 21 puntos clave (landmarks) con coordenadas x, y, z\npredictions se actualiza continuamente con las nuevas detecciones\n\n\n\n5. Visualizaci√≥n (draw)\nLa funci√≥n draw() se ejecuta continuamente y dibuja el video con los puntos de la mano:\nfunction draw() {\n    image(video, 0, 0, width, height);\n    \n    for (let i = 0; i &lt; predictions.length; i++) {\n        let prediction = predictions[i];\n        for (let j = 0; j &lt; prediction.landmarks.length; j++) {\n            let keypoint = prediction.landmarks[j];\n            fill(0, 255, 0);\n            noStroke();\n            circle(keypoint[0], keypoint[1], 10);\n        }\n    }\n}\n\nimage(video, 0, 0, width, height): Dibuja el frame actual del video\nPrimer bucle for: Itera sobre cada mano detectada\nSegundo bucle for: Itera sobre los 21 puntos clave de cada mano\nkeypoint[0], keypoint[1]: Coordenadas x, y de cada punto\ncircle(): Dibuja un c√≠rculo verde de 10 p√≠xeles en cada punto clave\nLos 21 puntos incluyen: mu√±eca, nudillos, articulaciones y puntas de los dedos",
    "crumbs": [
      "Ejemplos",
      "Detecci√≥n de Pose de Manos"
    ]
  },
  {
    "objectID": "ml5/object_detection.html",
    "href": "ml5/object_detection.html",
    "title": "Detecci√≥n de objetos",
    "section": "",
    "text": "Este modelo utiliza COCO-SSD (Common Objects in Context - Single Shot Detection) para identificar y localizar objetos en tiempo real. El modelo puede detectar 80 clases diferentes de objetos comunes como personas, animales, veh√≠culos, muebles y m√°s.\nInstrucciones:",
    "crumbs": [
      "Ejemplos",
      "Detecci√≥n de objetos"
    ]
  },
  {
    "objectID": "ml5/object_detection.html#explicaci√≥n-del-c√≥digo",
    "href": "ml5/object_detection.html#explicaci√≥n-del-c√≥digo",
    "title": "Detecci√≥n de objetos",
    "section": "Explicaci√≥n del C√≥digo",
    "text": "Explicaci√≥n del C√≥digo\n\nC√≥digo Completo\nlet video;\nlet detector;\nlet detections = [];\n\nfunction setup() {\n    createCanvas(640, 480);\n    \n    // Using webcam feed as video input\n    video = createCapture(VIDEO, videoReady);\n    video.size(width, height);\n    video.hide();\n}\n\nfunction videoReady() {\n    console.log(\"Video Ready!\");\n    // Create detector AFTER video is ready\n    detector = ml5.objectDetector('cocossd', modelReady);\n}\n\nfunction modelReady() {\n    console.log(\"Model Ready!\");\n    detect();\n}\n\nfunction detect() {\n    detector.detect(video, gotDetections);\n}\n\nfunction gotDetections(error, results) {\n    if (error) {\n        console.error(error);\n        return;\n    }\n    // Update detections array with the new results\n    detections = results;\n    // Call detect again for continuous detection\n    detect();\n}\n\nfunction draw() {\n    // Draw the current video frame onto the canvas\n    image(video, 0, 0);\n    \n    for (let i = 0; i &lt; detections.length; i++) {\n        let detection = detections[i];\n        \n        // Draw bounding box\n        stroke(0, 255, 0);\n        strokeWeight(4);\n        noFill();\n        rect(detection.x, detection.y, detection.width, detection.height);\n        \n        // Draw label\n        noStroke();\n        fill(255);\n        textSize(24);\n        text(detection.label, detection.x + 10, detection.y + 24);\n    }\n}\n\n\n1. Declaraci√≥n de Variables\nPrimero, declaramos las variables que necesitaremos durante todo el proceso:\nlet video;\nlet detector;\nlet detections = [];\n\nvideo: Almacenar√° la captura de la c√°mara web\ndetector: Contendr√° el modelo COCO-SSD de ml5.js\ndetections: Array que guardar√° los objetos detectados en cada frame\n\n\n\n2. Configuraci√≥n Inicial (setup)\nLa funci√≥n setup() se ejecuta una vez al inicio y configura el canvas y la c√°mara:\nfunction setup() {\n    createCanvas(640, 480);\n    video = createCapture(VIDEO, videoReady);\n    video.size(width, height);\n    video.hide();\n}\n\ncreateCanvas(640, 480): Crea un lienzo de 640x480 p√≠xeles para mostrar el video\ncreateCapture(VIDEO, videoReady): Captura el video de la webcam y llama a videoReady cuando est√© listo\nvideo.hide(): Oculta el elemento HTML del video (solo mostramos el canvas)\n\n\n\n3. Carga del Modelo (videoReady)\nEsta funci√≥n se ejecuta cuando el video est√° listo, garantizando que el detector tenga video para analizar:\nfunction videoReady() {\n    detector = ml5.objectDetector('cocossd', modelReady);\n}\n\nml5.objectDetector('cocossd', modelReady): Carga el modelo COCO-SSD pre-entrenado\nSe llama solo despu√©s de que el video est√© disponible para evitar errores\nCuando el modelo carga, llama autom√°ticamente a modelReady()\n\n\n\n4. Inicio de Detecci√≥n (modelReady y detect)\nEstas funciones inician el ciclo de detecci√≥n continua:\nfunction modelReady() {\n    detect();\n}\n\nfunction detect() {\n    detector.detect(video, gotDetections);\n}\n\ndetect(): Funci√≥n que inicia una detecci√≥n en el frame actual del video\ndetector.detect(video, gotDetections): Analiza el video y llama a gotDetections con los resultados\n\n\n\n5. Procesamiento de Resultados (gotDetections)\nEsta funci√≥n recibe los objetos detectados y mantiene la detecci√≥n continua:\nfunction gotDetections(error, results) {\n    if (error) {\n        console.error(error);\n        return;\n    }\n    detections = results;\n    detect();\n}\n\nerror: Contiene informaci√≥n si algo sali√≥ mal\nresults: Array con todos los objetos detectados en el frame\ndetections = results: Actualiza el array de detecciones\ndetect(): Llama recursivamente para detecci√≥n continua\n\n\n\n6. Visualizaci√≥n (draw)\nLa funci√≥n draw() se ejecuta continuamente y dibuja el video con las detecciones:\nfunction draw() {\n    image(video, 0, 0);\n    \n    for (let i = 0; i &lt; detections.length; i++) {\n        let detection = detections[i];\n        \n        // Draw bounding box\n        stroke(0, 255, 0);\n        strokeWeight(4);\n        noFill();\n        rect(detection.x, detection.y, detection.width, detection.height);\n        \n        // Draw label\n        noStroke();\n        fill(255);\n        textSize(24);\n        text(detection.label, detection.x + 10, detection.y + 24);\n    }\n}\n\nimage(video, 0, 0): Dibuja el frame actual del video en el canvas\nrect(): Dibuja un rect√°ngulo verde alrededor de cada objeto detectado\ntext(): Muestra la etiqueta del objeto (ej: ‚Äúperson‚Äù, ‚Äúcar‚Äù, ‚Äúdog‚Äù)\ndetection.x, detection.y, detection.width, detection.height: Coordenadas del objeto",
    "crumbs": [
      "Ejemplos",
      "Detecci√≥n de objetos"
    ]
  },
  {
    "objectID": "ml5/sound_classifier.html",
    "href": "ml5/sound_classifier.html",
    "title": "Clasificador de Sonido",
    "section": "",
    "text": "Este modelo utiliza SpeechCommands18w, entrenado para reconocer 18 palabras de comando en ingl√©s. El clasificador escucha continuamente a trav√©s de tu micr√≥fono y detecta cu√°l de las 18 palabras est√° siendo pronunciada.\nInstrucciones:",
    "crumbs": [
      "Ejemplos",
      "Clasificador de Sonido"
    ]
  },
  {
    "objectID": "ml5/sound_classifier.html#explicaci√≥n-del-c√≥digo",
    "href": "ml5/sound_classifier.html#explicaci√≥n-del-c√≥digo",
    "title": "Clasificador de Sonido",
    "section": "Explicaci√≥n del C√≥digo",
    "text": "Explicaci√≥n del C√≥digo\n\nC√≥digo Completo\nlet classifier;\n\n// Array containing the 18 words of SpeechCommands18w\nlet words = [\n    \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\",\n    \"up\", \"down\", \"left\", \"right\", \"go\", \"stop\", \"yes\", \"no\"\n];\n\n// Variable for displaying the results on the canvas\nlet predictedWord = \"\";\n\nfunction preload() {\n    // Options for the SpeechCommands18w model\n    let options = { probabilityThreshold: 0.7 };\n    // Load SpeechCommands18w sound classifier model\n    classifier = ml5.soundClassifier(\"SpeechCommands18w\", options);\n}\n\nfunction setup() {\n    createCanvas(650, 450);\n    // Classify the sound from microphone in real time\n    classifier.classifyStart(gotResult);\n}\n\nfunction draw() {\n    background(250);\n    // Call function for displaying background words\n    displayWords();\n    \n    // Once the model outputs results start displaying the predicted word\n    if (predictedWord !== \"\") {\n        fill(211, 107, 255);\n        textAlign(CENTER, CENTER);\n        textSize(64);\n        text(predictedWord, width / 2, 90);\n    }\n}\n\n// Function to display the 18 words on the canvas\nfunction displayWords() {\n    textAlign(CENTER, CENTER);\n    textSize(32);\n    fill(96);\n    text(\"Say one of these words!\", width / 2, 40);\n    \n    let x = 125;\n    let y = 150;\n    // Words appear in 3 columns of 6 rows\n    for (let i = 0; i &lt; words.length; i++) {\n        fill(158);\n        text(words[i], x, y);\n        y += 50;\n        if ((i + 1) % 6 === 0) {\n            x += 200;\n            y = 150;\n        }\n    }\n}\n\n// A function to run when we get any errors and the results\nfunction gotResult(results) {\n    // The results are in an array ordered by confidence\n    console.log(results);\n    // Load the first label to the text variable\n    if (results && results.length &gt; 0) {\n        predictedWord = results[0].label;\n    }\n}\n\n\n1. Declaraci√≥n de Variables\nPrimero, declaramos las variables que necesitaremos:\nlet classifier;\nlet words = [\n    \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\",\n    \"up\", \"down\", \"left\", \"right\", \"go\", \"stop\", \"yes\", \"no\"\n];\nlet predictedWord = \"\";\n\nclassifier: Almacenar√° el modelo SpeechCommands18w de ml5.js\nwords: Array con las 18 palabras que el modelo puede reconocer\npredictedWord: Guardar√° la √∫ltima palabra detectada por el modelo\n\n\n\n2. Carga del Modelo (preload)\nLa funci√≥n preload() carga el clasificador de sonido antes de iniciar:\nfunction preload() {\n    let options = { probabilityThreshold: 0.7 };\n    classifier = ml5.soundClassifier(\"SpeechCommands18w\", options);\n}\n\nprobabilityThreshold: 0.7: Solo acepta predicciones con 70% o m√°s de confianza\nml5.soundClassifier(\"SpeechCommands18w\"): Carga el modelo pre-entrenado con 18 comandos\nEsta funci√≥n garantiza que el modelo est√© listo antes de setup()\n\n\n\n3. Configuraci√≥n e Inicio de Clasificaci√≥n (setup)\nLa funci√≥n setup() configura el canvas e inicia la clasificaci√≥n continua:\nfunction setup() {\n    createCanvas(650, 450);\n    classifier.classifyStart(gotResult);\n}\n\ncreateCanvas(650, 450): Crea el lienzo para mostrar las palabras\nclassifyStart(gotResult): Inicia la clasificaci√≥n continua del audio del micr√≥fono\nCada vez que detecta un sonido, llama a gotResult() con los resultados\n\n\n\n4. Visualizaci√≥n (draw)\nLa funci√≥n draw() se ejecuta continuamente para mostrar la interfaz:\nfunction draw() {\n    background(250);\n    displayWords();\n    \n    if (predictedWord !== \"\") {\n        fill(211, 107, 255);\n        textAlign(CENTER, CENTER);\n        textSize(64);\n        text(predictedWord, width / 2, 90);\n    }\n}\n\nbackground(250): Limpia el canvas con un fondo gris claro\ndisplayWords(): Muestra las 18 palabras disponibles\ntext(predictedWord, ...): Muestra en grande la palabra detectada en color morado\n\n\n\n5. Mostrar Palabras Disponibles (displayWords)\nEsta funci√≥n dibuja todas las palabras que el usuario puede decir:\nfunction displayWords() {\n    textAlign(CENTER, CENTER);\n    textSize(32);\n    fill(96);\n    text(\"Say one of these words!\", width / 2, 40);\n    \n    let x = 125;\n    let y = 150;\n    for (let i = 0; i &lt; words.length; i++) {\n        fill(158);\n        text(words[i], x, y);\n        y += 50;\n        if ((i + 1) % 6 === 0) {\n            x += 200;\n            y = 150;\n        }\n    }\n}\n\nOrganiza las 18 palabras en 3 columnas de 6 filas\n(i + 1) % 6 === 0: Detecta cuando completar una columna\nMueve x a la derecha y resetea y al iniciar nueva columna\n\n\n\n6. Procesamiento de Resultados (gotResult)\nEsta funci√≥n recibe las predicciones del clasificador:\nfunction gotResult(results) {\n    console.log(results);\n    if (results && results.length &gt; 0) {\n        predictedWord = results[0].label;\n    }\n}\n\nresults: Array ordenado por nivel de confianza\nresults[0].label: La palabra con mayor probabilidad\nSe actualiza predictedWord que se muestra en draw()\nEsta funci√≥n se llama autom√°ticamente cada vez que hay una nueva predicci√≥n",
    "crumbs": [
      "Ejemplos",
      "Clasificador de Sonido"
    ]
  },
  {
    "objectID": "sesion1/0_parte_0.html",
    "href": "sesion1/0_parte_0.html",
    "title": "bootcamp-dci",
    "section": "",
    "text": "TipObjetivo de la sesi√≥n\n\n\n\nLa Sesi√≥n 1 est√° dedicada a comprender qu√© es una funcionalidad de software que clasifica im√°genes. El objetivo de esta sesi√≥n no es implementar c√≥digo en una aplicaci√≥n, sino construir una comprensi√≥n clara y ordenada del problema que se resolver√° en las siguientes sesiones.\n\n\nPara llegar a la clasificaci√≥n de im√°genes haremos tres cosas:\n\nComprenderemos el problema de la predicci√≥n\nEntenderemos qu√© significa implementar un clasificador\nAnalizaremos c√≥mo se hacen predicciones usando ese clasificador\n\nDurante esta sesi√≥n utilizaremos Teachable Machine (https://teachablemachine.withgoogle.com/) como herramienta de apoyo. Teachable Machine permite construir y probar clasificadores de im√°genes de forma visual, sin necesidad de programar, lo que facilita concentrarse en los conceptos de predicci√≥n y clasificaci√≥n antes de llevarlos a una implementaci√≥n en c√≥digo.\n\n\n\nIr a la secci√≥n\nEn esta primera parte se introduce el concepto de predicci√≥n desde una perspectiva de software. Se explica qu√© significa que un sistema produzca una predicci√≥n, qu√© tipo de resultados puede generar y por qu√© predecir no implica certeza, sino estimaci√≥n. Se utilizan ejemplos simples, como la predicci√≥n de temperatura o la clasificaci√≥n del estado del tiempo, para fijar estas ideas antes de trabajar con im√°genes.\n\n\n\n\nIr a la secci√≥n\nEn la segunda parte se aborda qu√© es un clasificador y qu√© implica implementarlo como una funcionalidad de software. Aqu√≠ se introduce el uso de Teachable Machine para crear un clasificador de im√°genes sencillo, con el fin de observar qu√© datos se utilizan, qu√© clases se definen y c√≥mo el sistema aprende a distinguir entre ellas. El foco est√° en comprender el rol del clasificador, no en los detalles t√©cnicos de entrenamiento.\n\n\n\n\nIr a la secci√≥n\nEn la tercera parte se analiza c√≥mo se utiliza un clasificador para producir predicciones. Usando el clasificador construido con Teachable Machine, se observa qu√© ocurre cuando se introduce una nueva imagen, c√≥mo se genera una predicci√≥n y c√≥mo debe interpretarse el resultado. Se enfatiza que la predicci√≥n es una estimaci√≥n, no una verdad absoluta.\n\nAl finalizar la Sesi√≥n 1, los estudiantes deber√≠an reconocer claramente estas tres piezas, entender c√≥mo se relacionan entre s√≠ y haber observado una funcionalidad completa de clasificaci√≥n de im√°genes en acci√≥n, aunque a√∫n sin c√≥digo. Esta comprensi√≥n conceptual ser√° la base directa para la implementaci√≥n pr√°ctica que se abordar√° en la Sesi√≥n 2.",
    "crumbs": [
      "Sesi√≥n 1",
      "Introducci√≥n ‚Äì Comprender una funcionalidad de clasificaci√≥n de im√°genes"
    ]
  },
  {
    "objectID": "sesion1/0_parte_0.html#introducci√≥n-comprender-una-funcionalidad-de-clasificaci√≥n-de-im√°genes",
    "href": "sesion1/0_parte_0.html#introducci√≥n-comprender-una-funcionalidad-de-clasificaci√≥n-de-im√°genes",
    "title": "bootcamp-dci",
    "section": "",
    "text": "TipObjetivo de la sesi√≥n\n\n\n\nLa Sesi√≥n 1 est√° dedicada a comprender qu√© es una funcionalidad de software que clasifica im√°genes. El objetivo de esta sesi√≥n no es implementar c√≥digo en una aplicaci√≥n, sino construir una comprensi√≥n clara y ordenada del problema que se resolver√° en las siguientes sesiones.\n\n\nPara llegar a la clasificaci√≥n de im√°genes haremos tres cosas:\n\nComprenderemos el problema de la predicci√≥n\nEntenderemos qu√© significa implementar un clasificador\nAnalizaremos c√≥mo se hacen predicciones usando ese clasificador\n\nDurante esta sesi√≥n utilizaremos Teachable Machine (https://teachablemachine.withgoogle.com/) como herramienta de apoyo. Teachable Machine permite construir y probar clasificadores de im√°genes de forma visual, sin necesidad de programar, lo que facilita concentrarse en los conceptos de predicci√≥n y clasificaci√≥n antes de llevarlos a una implementaci√≥n en c√≥digo.\n\n\n\nIr a la secci√≥n\nEn esta primera parte se introduce el concepto de predicci√≥n desde una perspectiva de software. Se explica qu√© significa que un sistema produzca una predicci√≥n, qu√© tipo de resultados puede generar y por qu√© predecir no implica certeza, sino estimaci√≥n. Se utilizan ejemplos simples, como la predicci√≥n de temperatura o la clasificaci√≥n del estado del tiempo, para fijar estas ideas antes de trabajar con im√°genes.\n\n\n\n\nIr a la secci√≥n\nEn la segunda parte se aborda qu√© es un clasificador y qu√© implica implementarlo como una funcionalidad de software. Aqu√≠ se introduce el uso de Teachable Machine para crear un clasificador de im√°genes sencillo, con el fin de observar qu√© datos se utilizan, qu√© clases se definen y c√≥mo el sistema aprende a distinguir entre ellas. El foco est√° en comprender el rol del clasificador, no en los detalles t√©cnicos de entrenamiento.\n\n\n\n\nIr a la secci√≥n\nEn la tercera parte se analiza c√≥mo se utiliza un clasificador para producir predicciones. Usando el clasificador construido con Teachable Machine, se observa qu√© ocurre cuando se introduce una nueva imagen, c√≥mo se genera una predicci√≥n y c√≥mo debe interpretarse el resultado. Se enfatiza que la predicci√≥n es una estimaci√≥n, no una verdad absoluta.\n\nAl finalizar la Sesi√≥n 1, los estudiantes deber√≠an reconocer claramente estas tres piezas, entender c√≥mo se relacionan entre s√≠ y haber observado una funcionalidad completa de clasificaci√≥n de im√°genes en acci√≥n, aunque a√∫n sin c√≥digo. Esta comprensi√≥n conceptual ser√° la base directa para la implementaci√≥n pr√°ctica que se abordar√° en la Sesi√≥n 2.",
    "crumbs": [
      "Sesi√≥n 1",
      "Introducci√≥n ‚Äì Comprender una funcionalidad de clasificaci√≥n de im√°genes"
    ]
  },
  {
    "objectID": "sesion1/2_parte_2.html",
    "href": "sesion1/2_parte_2.html",
    "title": "bootcamp-dci",
    "section": "",
    "text": "TipIdea clave\n\n\n\nEntender qu√© significa implementar un clasificador es el segundo paso para comprender una funcionalidad de clasificaci√≥n de im√°genes como parte de un sistema de software. En esta etapa, el foco no est√° en el entrenamiento ni en las matem√°ticas, sino en entender qu√© es un clasificador, qu√© decisiones implica y qu√© rol cumple dentro de la funcionalidad completa.\n\n\n\n\nUn clasificador puede entenderse como una funcionalidad de software que:\n\nRecibe datos de entrada\nProduce una categor√≠a como resultado\nDecide a cu√°l de las clases disponibles se parecen m√°s esos datos\n\nSu tarea no es describir los datos ni interpretarlos de forma humana, sino tomar una decisi√≥n categ√≥rica.\nEn el contexto de im√°genes, esto significa decidir, por ejemplo, si una imagen:\n\nPertenece a una clase u otra\n\nSe parece m√°s a un conjunto de ejemplos que a otro\n\n\n\n\nSiguiendo el ejemplo del clima usado anteriormente, un clasificador funciona de forma similar a una persona que, despu√©s de observar muchas veces las condiciones del d√≠a, decide si el clima ser√°:\n\n‚ÄúBueno‚Äù\n‚ÄúMalo‚Äù\n\nEl clasificador:\n\nNo calcula grados\n\nNo explica por qu√© ocurre el fen√≥meno\n\nSolo observa los datos y elige la categor√≠a m√°s parecida a lo que ha visto antes\n\nEn el caso de im√°genes, el proceso es equivalente: el sistema recibe una imagen nueva y decide si se parece m√°s a los ejemplos de una clase u otra, produciendo as√≠ una predicci√≥n categ√≥rica.\n\n\n\nImplementar un clasificador implica, en primer lugar, definir las clases del problema. Esto es una decisi√≥n de dise√±o, no algo autom√°tico.\nAl definir las clases, el desarrollador decide:\n\nQu√© categor√≠as existen\n\nQu√© diferencia a una clase de otra\n\nQu√© tipo de predicciones podr√° producir el sistema\n\nEstas decisiones influyen directamente en el comportamiento del clasificador.\n\n\n\nEn segundo lugar, implementar un clasificador implica decidir qu√© datos se utilizar√°n como entrada.\nEn el caso de im√°genes:\n\nEl sistema no recibe ‚Äúobjetos‚Äù ni ‚Äúformas‚Äù\nRecibe datos num√©ricos que representan la imagen\nEl clasificador siempre trabaja con datos, no con significados\n\nAunque estas transformaciones se ocultan en herramientas modernas, es importante tener presente esta idea.\n\n\n\nPara explorar estos conceptos de manera concreta, en esta parte se utiliza Teachable Machine:\nhttps://teachablemachine.withgoogle.com/\nTeachable Machine permite crear un clasificador de im√°genes de forma visual, sin escribir c√≥digo, lo que facilita observar el proceso completo. Con esta herramienta es posible:\n\nDefinir expl√≠citamente las clases üè∑Ô∏è\n\nProporcionar ejemplos para cada clase üñºÔ∏è\n\nVer c√≥mo el sistema empieza a distinguir patrones üîç\n\nEl objetivo de usar Teachable Machine no es entrenar modelos, sino hacer visible qu√© significa implementar un clasificador como funcionalidad de software.\n\n\n\nImplementar un clasificador no garantiza resultados correctos. El sistema puede equivocarse, especialmente cuando:\n\nLas clases est√°n mal definidas\n\nLos ejemplos no representan bien el problema\n\nLas clases se parecen demasiado entre s√≠\n\nEsto muestra que la calidad del clasificador depende directamente de las decisiones de dise√±o tomadas durante su implementaci√≥n.",
    "crumbs": [
      "Sesi√≥n 1",
      "üß† Qu√© significa implementar un clasificador"
    ]
  },
  {
    "objectID": "sesion1/2_parte_2.html#qu√©-significa-implementar-un-clasificador",
    "href": "sesion1/2_parte_2.html#qu√©-significa-implementar-un-clasificador",
    "title": "bootcamp-dci",
    "section": "",
    "text": "TipIdea clave\n\n\n\nEntender qu√© significa implementar un clasificador es el segundo paso para comprender una funcionalidad de clasificaci√≥n de im√°genes como parte de un sistema de software. En esta etapa, el foco no est√° en el entrenamiento ni en las matem√°ticas, sino en entender qu√© es un clasificador, qu√© decisiones implica y qu√© rol cumple dentro de la funcionalidad completa.\n\n\n\n\nUn clasificador puede entenderse como una funcionalidad de software que:\n\nRecibe datos de entrada\nProduce una categor√≠a como resultado\nDecide a cu√°l de las clases disponibles se parecen m√°s esos datos\n\nSu tarea no es describir los datos ni interpretarlos de forma humana, sino tomar una decisi√≥n categ√≥rica.\nEn el contexto de im√°genes, esto significa decidir, por ejemplo, si una imagen:\n\nPertenece a una clase u otra\n\nSe parece m√°s a un conjunto de ejemplos que a otro\n\n\n\n\nSiguiendo el ejemplo del clima usado anteriormente, un clasificador funciona de forma similar a una persona que, despu√©s de observar muchas veces las condiciones del d√≠a, decide si el clima ser√°:\n\n‚ÄúBueno‚Äù\n‚ÄúMalo‚Äù\n\nEl clasificador:\n\nNo calcula grados\n\nNo explica por qu√© ocurre el fen√≥meno\n\nSolo observa los datos y elige la categor√≠a m√°s parecida a lo que ha visto antes\n\nEn el caso de im√°genes, el proceso es equivalente: el sistema recibe una imagen nueva y decide si se parece m√°s a los ejemplos de una clase u otra, produciendo as√≠ una predicci√≥n categ√≥rica.\n\n\n\nImplementar un clasificador implica, en primer lugar, definir las clases del problema. Esto es una decisi√≥n de dise√±o, no algo autom√°tico.\nAl definir las clases, el desarrollador decide:\n\nQu√© categor√≠as existen\n\nQu√© diferencia a una clase de otra\n\nQu√© tipo de predicciones podr√° producir el sistema\n\nEstas decisiones influyen directamente en el comportamiento del clasificador.\n\n\n\nEn segundo lugar, implementar un clasificador implica decidir qu√© datos se utilizar√°n como entrada.\nEn el caso de im√°genes:\n\nEl sistema no recibe ‚Äúobjetos‚Äù ni ‚Äúformas‚Äù\nRecibe datos num√©ricos que representan la imagen\nEl clasificador siempre trabaja con datos, no con significados\n\nAunque estas transformaciones se ocultan en herramientas modernas, es importante tener presente esta idea.\n\n\n\nPara explorar estos conceptos de manera concreta, en esta parte se utiliza Teachable Machine:\nhttps://teachablemachine.withgoogle.com/\nTeachable Machine permite crear un clasificador de im√°genes de forma visual, sin escribir c√≥digo, lo que facilita observar el proceso completo. Con esta herramienta es posible:\n\nDefinir expl√≠citamente las clases üè∑Ô∏è\n\nProporcionar ejemplos para cada clase üñºÔ∏è\n\nVer c√≥mo el sistema empieza a distinguir patrones üîç\n\nEl objetivo de usar Teachable Machine no es entrenar modelos, sino hacer visible qu√© significa implementar un clasificador como funcionalidad de software.\n\n\n\nImplementar un clasificador no garantiza resultados correctos. El sistema puede equivocarse, especialmente cuando:\n\nLas clases est√°n mal definidas\n\nLos ejemplos no representan bien el problema\n\nLas clases se parecen demasiado entre s√≠\n\nEsto muestra que la calidad del clasificador depende directamente de las decisiones de dise√±o tomadas durante su implementaci√≥n.",
    "crumbs": [
      "Sesi√≥n 1",
      "üß† Qu√© significa implementar un clasificador"
    ]
  },
  {
    "objectID": "sesion2/0_s2_parte_0.html",
    "href": "sesion2/0_s2_parte_0.html",
    "title": "bootcamp-dci",
    "section": "",
    "text": "En esta sesi√≥n trabajamos en la implementaci√≥n y an√°lisis de una funcionalidad de clasificaci√≥n de im√°genes dentro de una aplicaci√≥n de software. El foco est√° en c√≥mo una aplicaci√≥n integra un modelo de inteligencia artificial y utiliza sus resultados, no en entrenar modelos ni en estudiar teor√≠a de inteligencia artificial.\nEl objetivo de la sesi√≥n es comprender c√≥mo una funcionalidad basada en IA se incorpora a un sistema de software real, identificando sus componentes, su flujo de ejecuci√≥n y las decisiones de dise√±o involucradas.\nEl trabajo de la sesi√≥n se organiza en dos casos complementarios, dise√±ados para comparar enfoques habituales en el desarrollo de software que integra modelos de aprendizaje autom√°tico ya existentes.",
    "crumbs": [
      "Sesi√≥n 2",
      "Implementaci√≥n de una funcionalidad de clasificaci√≥n de im√°genes üñºÔ∏èü§ñ"
    ]
  },
  {
    "objectID": "sesion2/0_s2_parte_0.html#implementaci√≥n-de-una-funcionalidad-de-clasificaci√≥n-de-im√°genes",
    "href": "sesion2/0_s2_parte_0.html#implementaci√≥n-de-una-funcionalidad-de-clasificaci√≥n-de-im√°genes",
    "title": "bootcamp-dci",
    "section": "",
    "text": "En esta sesi√≥n trabajamos en la implementaci√≥n y an√°lisis de una funcionalidad de clasificaci√≥n de im√°genes dentro de una aplicaci√≥n de software. El foco est√° en c√≥mo una aplicaci√≥n integra un modelo de inteligencia artificial y utiliza sus resultados, no en entrenar modelos ni en estudiar teor√≠a de inteligencia artificial.\nEl objetivo de la sesi√≥n es comprender c√≥mo una funcionalidad basada en IA se incorpora a un sistema de software real, identificando sus componentes, su flujo de ejecuci√≥n y las decisiones de dise√±o involucradas.\nEl trabajo de la sesi√≥n se organiza en dos casos complementarios, dise√±ados para comparar enfoques habituales en el desarrollo de software que integra modelos de aprendizaje autom√°tico ya existentes.",
    "crumbs": [
      "Sesi√≥n 2",
      "Implementaci√≥n de una funcionalidad de clasificaci√≥n de im√°genes üñºÔ∏èü§ñ"
    ]
  },
  {
    "objectID": "sesion2/0_s2_parte_0.html#herramientas-de-trabajo",
    "href": "sesion2/0_s2_parte_0.html#herramientas-de-trabajo",
    "title": "bootcamp-dci",
    "section": "Herramientas de trabajo",
    "text": "Herramientas de trabajo\n\n\n\n\n\n\nNota\n\n\n\nDurante toda la sesi√≥n se utiliza Visual Studio Code (VS Code) como editor de c√≥digo.\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nEs obligatorio instalar la extensi√≥n Live Server (Go Live) en VS Code y ejecutar los ejemplos usando esta herramienta.\nLa extensi√≥n puede instalarse desde el Marketplace de Visual Studio Code en el siguiente enlace:\nLive Server ‚Äì Visual Studio Code Marketplace\nAlternativamente, la extensi√≥n puede buscarse directamente desde el buscador de extensiones de VS Code, escribiendo Live Server.",
    "crumbs": [
      "Sesi√≥n 2",
      "Implementaci√≥n de una funcionalidad de clasificaci√≥n de im√°genes üñºÔ∏èü§ñ"
    ]
  },
  {
    "objectID": "sesion2/0_s2_parte_0.html#estructura-de-la-sesi√≥n",
    "href": "sesion2/0_s2_parte_0.html#estructura-de-la-sesi√≥n",
    "title": "bootcamp-dci",
    "section": "Estructura de la sesi√≥n",
    "text": "Estructura de la sesi√≥n\nDurante la sesi√≥n se trabajan dos casos pr√°cticos:\n\nCaso 1: implementaci√≥n de una funcionalidad de clasificaci√≥n de im√°genes que utiliza un modelo entrenado en Teachable Machine y procesa video capturado desde la c√°mara.\nCaso 2: implementaci√≥n de una funcionalidad de clasificaci√≥n que utiliza un modelo preentrenado y procesa una imagen fija.\n\n\n\n\n\n\n\nTip\n\n\n\nAunque ambos casos resuelven el mismo problema general ‚Äîclasificar im√°genes‚Äî, parten de supuestos distintos sobre el modelo y la entrada de datos. Esta diferencia es clave para entender decisiones de dise√±o en aplicaciones de software que incorporan IA.\n\n\nCada caso se aborda por separado, analizando su funcionamiento, sus limitaciones y las implicancias que tiene el tipo de modelo utilizado en el comportamiento de la aplicaci√≥n.",
    "crumbs": [
      "Sesi√≥n 2",
      "Implementaci√≥n de una funcionalidad de clasificaci√≥n de im√°genes üñºÔ∏èü§ñ"
    ]
  },
  {
    "objectID": "sesion2/0_s2_parte_0.html#resultado-esperado-de-la-sesi√≥n",
    "href": "sesion2/0_s2_parte_0.html#resultado-esperado-de-la-sesi√≥n",
    "title": "bootcamp-dci",
    "section": "Resultado esperado de la sesi√≥n",
    "text": "Resultado esperado de la sesi√≥n\nAl finalizar la sesi√≥n deber√≠as ser capaz de describir c√≥mo se implementa una funcionalidad de clasificaci√≥n de im√°genes dentro de una aplicaci√≥n de software, identificar el rol que cumple el modelo de IA en el sistema y explicar las diferencias pr√°cticas entre trabajar con modelos entrenados espec√≠ficamente y modelos preentrenados reutilizables.",
    "crumbs": [
      "Sesi√≥n 2",
      "Implementaci√≥n de una funcionalidad de clasificaci√≥n de im√°genes üñºÔ∏èü§ñ"
    ]
  },
  {
    "objectID": "sesion2/2_s2_parte_2.html",
    "href": "sesion2/2_s2_parte_2.html",
    "title": "bootcamp-dci",
    "section": "",
    "text": "En este caso analizamos una funcionalidad de clasificaci√≥n de im√°genes que utiliza un modelo preentrenado y procesa una imagen fija, sin capturar im√°genes desde la c√°mara. A diferencia del Caso 1, el desarrollador no entrena ni ajusta el modelo, sino que reutiliza un modelo gen√©rico ya existente.\nEl objetivo de este caso es comprender c√≥mo una aplicaci√≥n de software integra un modelo preentrenado y utiliza sus predicciones para clasificar una imagen puntual.",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 2 ‚Äì Clasificaci√≥n de una imagen usando un modelo preentrenado"
    ]
  },
  {
    "objectID": "sesion2/2_s2_parte_2.html#caso-2-clasificaci√≥n-de-una-imagen-usando-un-modelo-preentrenado",
    "href": "sesion2/2_s2_parte_2.html#caso-2-clasificaci√≥n-de-una-imagen-usando-un-modelo-preentrenado",
    "title": "bootcamp-dci",
    "section": "",
    "text": "En este caso analizamos una funcionalidad de clasificaci√≥n de im√°genes que utiliza un modelo preentrenado y procesa una imagen fija, sin capturar im√°genes desde la c√°mara. A diferencia del Caso 1, el desarrollador no entrena ni ajusta el modelo, sino que reutiliza un modelo gen√©rico ya existente.\nEl objetivo de este caso es comprender c√≥mo una aplicaci√≥n de software integra un modelo preentrenado y utiliza sus predicciones para clasificar una imagen puntual.",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 2 ‚Äì Clasificaci√≥n de una imagen usando un modelo preentrenado"
    ]
  },
  {
    "objectID": "sesion2/2_s2_parte_2.html#ejemplo-base",
    "href": "sesion2/2_s2_parte_2.html#ejemplo-base",
    "title": "bootcamp-dci",
    "section": "Ejemplo base",
    "text": "Ejemplo base\nüëâ Ejemplo de clasificaci√≥n con modelo preentrenado\nEste ejemplo muestra una aplicaci√≥n web que:\n\ncarga una imagen como entrada,\nejecuta una clasificaci√≥n sobre esa imagen,\ny muestra la etiqueta correspondiente como resultado.",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 2 ‚Äì Clasificaci√≥n de una imagen usando un modelo preentrenado"
    ]
  },
  {
    "objectID": "sesion2/2_s2_parte_2.html#trabajo-local",
    "href": "sesion2/2_s2_parte_2.html#trabajo-local",
    "title": "bootcamp-dci",
    "section": "Trabajo local",
    "text": "Trabajo local\nPara trabajar este caso durante la sesi√≥n, se utiliza una versi√≥n local del ejemplo.\nSe entrega un archivo comprimido (.zip) que contiene los archivos necesarios para ejecutar la funcionalidad de manera local. Algunos archivos adicionales est√°n incluidos √∫nicamente para asegurar compatibilidad con el entorno de ejecuci√≥n y no requieren modificaciones durante la sesi√≥n.\nAbre la carpeta en Visual Studio Code y ejecuta Go Live para iniciar el servidor local y abrir la aplicaci√≥n en el navegador.\nüëâ Descargar c√≥digo del Caso 2",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 2 ‚Äì Clasificaci√≥n de una imagen usando un modelo preentrenado"
    ]
  },
  {
    "objectID": "sesion2/2_s2_parte_2.html#funcionamiento-general-de-la-funcionalidad",
    "href": "sesion2/2_s2_parte_2.html#funcionamiento-general-de-la-funcionalidad",
    "title": "bootcamp-dci",
    "section": "Funcionamiento general de la funcionalidad",
    "text": "Funcionamiento general de la funcionalidad\nDesde el punto de vista del software, la funcionalidad implementa el siguiente flujo:\n\nla aplicaci√≥n carga una imagen fija,\nla imagen se entrega al modelo de clasificaci√≥n,\nel modelo produce una etiqueta como salida,\nla aplicaci√≥n muestra el resultado al usuario.\n\n\n\n\n\n\n\nTip\n\n\n\nEn este caso, el comportamiento del sistema depende completamente del modelo reutilizado. La aplicaci√≥n no controla las clases posibles ni los datos utilizados durante el entrenamiento.",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 2 ‚Äì Clasificaci√≥n de una imagen usando un modelo preentrenado"
    ]
  },
  {
    "objectID": "sesion2/2_s2_parte_2.html#en-qu√©-nos-fijamos-durante-el-an√°lisis",
    "href": "sesion2/2_s2_parte_2.html#en-qu√©-nos-fijamos-durante-el-an√°lisis",
    "title": "bootcamp-dci",
    "section": "En qu√© nos fijamos durante el an√°lisis",
    "text": "En qu√© nos fijamos durante el an√°lisis\nDurante el trabajo con este caso, nos enfocamos en observar:\n\nqu√© implica integrar un modelo preentrenado en una aplicaci√≥n de software,\nqu√© tipo de categor√≠as reconoce el modelo,\nqu√© informaci√≥n devuelve el clasificador para una imagen fija,\nqu√© limitaciones aparecen al no controlar el entrenamiento ni el contexto.\n\nEl foco est√° en las implicancias de dise√±o, no en la precisi√≥n del resultado ni en la interpretaci√≥n sem√°ntica de la imagen.",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 2 ‚Äì Clasificaci√≥n de una imagen usando un modelo preentrenado"
    ]
  },
  {
    "objectID": "sesion2/2_s2_parte_2.html#relaci√≥n-con-la-sesi√≥n",
    "href": "sesion2/2_s2_parte_2.html#relaci√≥n-con-la-sesi√≥n",
    "title": "bootcamp-dci",
    "section": "Relaci√≥n con la sesi√≥n",
    "text": "Relaci√≥n con la sesi√≥n\nEste caso complementa el Caso 1 al mostrar un enfoque distinto para implementar una funcionalidad de clasificaci√≥n de im√°genes. Comparar ambos casos permite entender c√≥mo el tipo de modelo y el tipo de entrada influyen directamente en el dise√±o y el comportamiento de la aplicaci√≥n.",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 2 ‚Äì Clasificaci√≥n de una imagen usando un modelo preentrenado"
    ]
  },
  {
    "objectID": "classification/classification_keylogger.html",
    "href": "classification/classification_keylogger.html",
    "title": "Keylogger detection",
    "section": "",
    "text": "PLANNING: - INTRO - short dataset description. - EDA - shape, dtypes, missing, class balance, sample rows, correlations. - PREPARING DATA - drop useless columns, fix dtype issues, parse timestamps, coerce numerics, encode label. - DATA SPLITTING - splitting training and testing data. - RESULTS - early results. - PREPARING MODELS - prepare hyperparameter, baseline models., baseline models. - RESULTS WITH MULTIPLES MODELS- metrics (precision/recall/f1), confusion matrix. - BALANCING - try balancing and compare. - RESULTS (after balancing) - compare metrics. - CONCLUSION - state best model, tradeoffs, next steps."
  },
  {
    "objectID": "classification/classification_keylogger.html#importamos-las-librer√≠as-necesarias-y-cargamos-el-dataset",
    "href": "classification/classification_keylogger.html#importamos-las-librer√≠as-necesarias-y-cargamos-el-dataset",
    "title": "Keylogger detection",
    "section": "Importamos las librer√≠as necesarias y cargamos el dataset",
    "text": "Importamos las librer√≠as necesarias y cargamos el dataset\n\nimport pandas as pd\nfrom pathlib import Path\n\nbase_dir = Path.cwd()\ncsv_file_path = base_dir.parent.parent / \"data\" / \"keylogger_detection\" / \"Keylogger_Detection_sample.csv\"\ndata = pd.read_csv(csv_file_path, low_memory=False, index_col=0)\n# Para hacer m√°s r√°pido el procesamiento, tomamos una muestra del dataset\ndf = data.sample(n=1000, random_state=42)\ndf.head(1)\n\n\n\n\n\n\n\n\nSource IP\nSource Port\nDestination IP\nDestination Port\nProtocol\nTimestamp\nFlow Duration\nTotal Fwd Packets\nTotal Backward Packets\nTotal Length of Fwd Packets\n...\nmin_seg_size_forward\nActive Mean\nActive Std\nActive Max\nActive Min\nIdle Mean\nIdle Std\nIdle Max\nIdle Min\nClass\n\n\nFlow ID\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n172.217.11.34-10.42.0.211-443-32906-6\n10.42.0.211\n32906.0\n172.217.11.34\n443.0\n6.0\n12/07/2017 02:05:31\n4508467.0\n2.0\n0.0\n0.0\n...\n32.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nKeylogger\n\n\n\n\n1 rows √ó 84 columns"
  },
  {
    "objectID": "classification/classification_keylogger.html#realizamos-un-analisis-exploratorio-sobre-los-datos",
    "href": "classification/classification_keylogger.html#realizamos-un-analisis-exploratorio-sobre-los-datos",
    "title": "Keylogger detection",
    "section": "Realizamos un analisis exploratorio sobre los datos",
    "text": "Realizamos un analisis exploratorio sobre los datos\n\nExploramos la forma general del dataset\n\n# Realizamos un analysis exploratorio sobre los datos\nn = 5\nprint(\"Shape:\", df.shape)\nprint(\"\\nColumns and dtypes:\")\nprint(df.dtypes)\nprint(\"\\nNumeric summary (describe):\")\ndisplay(df.describe().T)\n\nShape: (1000, 84)\n\nColumns and dtypes:\n Source IP            object\n Source Port         float64\n Destination IP       object\n Destination Port    float64\n Protocol            float64\n                      ...   \nIdle Mean            float64\n Idle Std            float64\n Idle Max            float64\n Idle Min            float64\nClass                 object\nLength: 84, dtype: object\n\nNumeric summary (describe):\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nSource Port\n1000.0\n3.815298e+04\n1.877217e+04\n0.0\n34250.75\n42899.5\n51987.25\n6.490400e+04\n\n\nDestination Port\n1000.0\n6.729693e+03\n1.652872e+04\n0.0\n80.00\n443.0\n443.00\n6.096000e+04\n\n\nProtocol\n1000.0\n7.806000e+00\n4.163616e+00\n0.0\n6.00\n6.0\n6.00\n1.700000e+01\n\n\nFlow Duration\n1000.0\n1.129487e+07\n2.334697e+07\n2.0\n39036.00\n471797.5\n10096081.50\n1.199892e+08\n\n\nTotal Fwd Packets\n1000.0\n7.618000e+00\n2.790492e+01\n1.0\n1.00\n2.0\n6.00\n7.050000e+02\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nActive Min\n1000.0\n1.704751e+05\n1.716989e+06\n0.0\n0.00\n0.0\n0.00\n4.993167e+07\n\n\nIdle Mean\n1000.0\n4.599871e+06\n1.548024e+07\n0.0\n0.00\n0.0\n0.00\n1.145099e+08\n\n\nIdle Std\n1000.0\n4.484078e+05\n3.680408e+06\n0.0\n0.00\n0.0\n0.00\n4.708189e+07\n\n\nIdle Max\n1000.0\n4.972753e+06\n1.636404e+07\n0.0\n0.00\n0.0\n0.00\n1.145099e+08\n\n\nIdle Min\n1000.0\n4.254974e+06\n1.512216e+07\n0.0\n0.00\n0.0\n0.00\n1.145099e+08\n\n\n\n\n80 rows √ó 8 columns\n\n\n\n\n\nVerificamos valores nulos\n\n# Resumen de valores nulos\n\nmissing_counts = df.isna().sum()\nmissing_percent = 100 * missing_counts / len(df)\nmissing_summary = pd.concat([missing_counts, missing_percent], axis=1)\nmissing_summary.columns = [\"nulos\", \"porcentaje\"]\nprint(\"\\nNulos por columna (n y %):\")\ndisplay(missing_summary.sort_values(\"nulos\", ascending=False).head(20))\n\n\nNulos por columna (n y %):\n\n\n\n\n\n\n\n\n\nnulos\nporcentaje\n\n\n\n\nSource IP\n0\n0.0\n\n\nURG Flag Count\n0\n0.0\n\n\nFwd Avg Bytes/Bulk\n0\n0.0\n\n\nFwd Header Length.1\n0\n0.0\n\n\nAvg Bwd Segment Size\n0\n0.0\n\n\nAvg Fwd Segment Size\n0\n0.0\n\n\nAverage Packet Size\n0\n0.0\n\n\nDown/Up Ratio\n0\n0.0\n\n\nECE Flag Count\n0\n0.0\n\n\nCWE Flag Count\n0\n0.0\n\n\nACK Flag Count\n0\n0.0\n\n\nSource Port\n0\n0.0\n\n\nPSH Flag Count\n0\n0.0\n\n\nRST Flag Count\n0\n0.0\n\n\nSYN Flag Count\n0\n0.0\n\n\nFIN Flag Count\n0\n0.0\n\n\nPacket Length Variance\n0\n0.0\n\n\nPacket Length Std\n0\n0.0\n\n\nPacket Length Mean\n0\n0.0\n\n\nMax Packet Length\n0\n0.0\n\n\n\n\n\n\n\nRevisamos su distribution\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ntarget_col = \"Class\"\nfigsize = (6, 4)\n\n# Muestra los conteos y porcentajes para la variable binaria objetivo\n\nvc = df[target_col].value_counts(dropna=False)\npct = (vc / len(df) * 100).round(2)\nprint(\"Counts:\")\nprint(vc)\nprint(\"\\nPercent:\")\nprint(pct)\n\nplt.figure(figsize=figsize)\nsns.barplot(x=vc.index.astype(str), y=vc.values)\nplt.title(f\"Target distribution: {target_col}\")\nplt.ylabel(\"count\")\nplt.xlabel(target_col)\nplt.show()\n\nCounts:\nClass\nBenign       620\nKeylogger    380\nName: count, dtype: int64\n\nPercent:\nClass\nBenign       62.0\nKeylogger    38.0\nName: count, dtype: float64"
  },
  {
    "objectID": "classification/classification_software_defects.html",
    "href": "classification/classification_software_defects.html",
    "title": "Software Defects analysis",
    "section": "",
    "text": "Software Defects Multilingual Dataset with AST & Token Features (2025), un conjunto de datos sint√©tico dise√±ado para el estudio de predicci√≥n de defectos en software y la an√°lisis est√°tico de c√≥digo en m√∫ltiples lenguajes de programaci√≥n. Predecimoses entrenar modelos de machine learning capaces de predecir si una funci√≥n de c√≥digo contiene defectos o no, bas√°ndose en m√©tricas est√°ticas (tokens, complejidad, estructuras de control, etc.).\nPLANNING: - INTRO - short dataset description. - EDA - shape, dtypes, missing, class balance, sample rows, correlations. - PREPARING DATA - drop useless columns, fix dtype issues, parse timestamps, coerce numerics, encode label. - DATA SPLITTING - splitting training and testing data. - RESULTS - early results. - PREPARING MODELS - prepare hyperparameter, baseline models. - RESULTS WITH MULTIPLES MODELS- metrics (precision/recall/f1), confusion matrix. - BALANCING - try balancing and compare. - RESULTS (after balancing) - compare metrics. - CONCLUSION - state best model, tradeoffs, next steps."
  },
  {
    "objectID": "classification/classification_software_defects.html#importamos-las-librer√≠as-necesarias-y-cargamos-el-dataset",
    "href": "classification/classification_software_defects.html#importamos-las-librer√≠as-necesarias-y-cargamos-el-dataset",
    "title": "Software Defects analysis",
    "section": "Importamos las librer√≠as necesarias y cargamos el dataset",
    "text": "Importamos las librer√≠as necesarias y cargamos el dataset\n\nimport pandas as pd\nfrom pathlib import Path\n\nbase_dir = Path.cwd()\ncsv_file_path = base_dir.parent.parent / \"data\" / \"software_defects\" / \"software_defects.csv\"\ndf = pd.read_csv(csv_file_path, low_memory=False, index_col=0)\ndf.head(1)\n\n\n\n\n\n\n\n\ncode\nlanguage\nlines_of_code\ncyclomatic_complexity\ntoken_count\nnum_ifs\nnum_returns\nnum_func_calls\nast_nodes\ndefect\n\n\nfunction_name\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngo_func_0\nfunc add(a int, b int) int { return a + b }\ngo\n2\n2\n12\n0\n1\n1\n12\n0"
  },
  {
    "objectID": "classification/classification_software_defects.html#realizamos-un-analisis-exploratorio-sobre-los-datos",
    "href": "classification/classification_software_defects.html#realizamos-un-analisis-exploratorio-sobre-los-datos",
    "title": "Software Defects analysis",
    "section": "Realizamos un analisis exploratorio sobre los datos",
    "text": "Realizamos un analisis exploratorio sobre los datos\n\nExploramos la forma general del dataset\n\n# Realizamos un analysis exploratorio sobre los datos\nprint(\"Shape:\", df.shape)\nprint(\"\\nColumns and dtypes:\")\nprint(df.dtypes)\nprint(\"\\nNumeric summary (describe):\")\ndisplay(df.describe().T)\n\nShape: (1000, 10)\n\nColumns and dtypes:\ncode                     object\nlanguage                 object\nlines_of_code             int64\ncyclomatic_complexity     int64\ntoken_count               int64\nnum_ifs                   int64\nnum_returns               int64\nnum_func_calls            int64\nast_nodes                 int64\ndefect                    int64\ndtype: object\n\nNumeric summary (describe):\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nlines_of_code\n1000.0\n3.431\n1.708847\n1.0\n2.0\n3.0\n5.0\n6.0\n\n\ncyclomatic_complexity\n1000.0\n2.914\n1.394471\n1.0\n2.0\n3.0\n4.0\n5.0\n\n\ntoken_count\n1000.0\n11.622\n1.809528\n9.0\n11.0\n12.0\n12.0\n18.0\n\n\nnum_ifs\n1000.0\n0.000\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nnum_returns\n1000.0\n0.856\n0.351265\n0.0\n1.0\n1.0\n1.0\n1.0\n\n\nnum_func_calls\n1000.0\n0.972\n0.365170\n0.0\n1.0\n1.0\n1.0\n2.0\n\n\nast_nodes\n1000.0\n11.622\n1.809528\n9.0\n11.0\n12.0\n12.0\n18.0\n\n\ndefect\n1000.0\n0.512\n0.500106\n0.0\n0.0\n1.0\n1.0\n1.0\n\n\n\n\n\n\n\n\n\nVerificamos valores nulos\n\n# Resumen de valores nulos\n\nmissing_counts = df.isna().sum()\nmissing_percent = 100 * missing_counts / len(df)\nmissing_summary = pd.concat([missing_counts, missing_percent], axis=1)\nmissing_summary.columns = [\"nulos\", \"porcentaje\"]\nprint(\"\\nNulos por columna (n y %):\")\ndisplay(missing_summary.sort_values(\"nulos\", ascending=False).head(20))\n\n\nNulos por columna (n y %):\n\n\n\n\n\n\n\n\n\nnulos\nporcentaje\n\n\n\n\ncode\n0\n0.0\n\n\nlanguage\n0\n0.0\n\n\nlines_of_code\n0\n0.0\n\n\ncyclomatic_complexity\n0\n0.0\n\n\ntoken_count\n0\n0.0\n\n\nnum_ifs\n0\n0.0\n\n\nnum_returns\n0\n0.0\n\n\nnum_func_calls\n0\n0.0\n\n\nast_nodes\n0\n0.0\n\n\ndefect\n0\n0.0\n\n\n\n\n\n\n\nRevisamos su distribution\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ntarget_col = \"defect\"\nfigsize = (6, 4)\n\n# Muestra los conteos y porcentajes para la variable binaria objetivo\n\nvc = df[target_col].value_counts(dropna=False)\npct = (vc / len(df) * 100).round(2)\nprint(\"Counts:\")\nprint(vc)\nprint(\"\\nPercent:\")\nprint(pct)\n\nplt.figure(figsize=figsize)\nsns.barplot(x=vc.index.astype(str), y=vc.values)\nplt.title(f\"Target distribution: {target_col}\")\nplt.ylabel(\"count\")\nplt.xlabel(target_col)\nplt.show()\n\nCounts:\ndefect\n1    512\n0    488\nName: count, dtype: int64\n\nPercent:\ndefect\n1    51.2\n0    48.8\nName: count, dtype: float64"
  },
  {
    "objectID": "classification/classification_ransomware.html",
    "href": "classification/classification_ransomware.html",
    "title": "Ransomware detection",
    "section": "",
    "text": "Este dataset contiene 21,752 muestras balanceadas, de las cuales 10,876 son maliciosas y 10,876 benignas. Las muestras maliciosas est√°n distribuidas en 26 familias distintas, incluyendo un enfoque particular en ransomware, con familias reconocidas como Cerber, DarkSide, GandCrab, Ryuk y WannaCry, entre otras.\nEl objetivo principal es entrenar modelos de clasificaci√≥n capaces de distinguir entre archivos maliciosos y benignos, evaluando su desempe√±o mediante m√©tricas como precisi√≥n, recall, f1-score y exactitud.\nEl dataset contiene caracter√≠sticas relevantes de cada archivo, que ser√°n procesadas, limpiadas y transformadas para generar los conjuntos de entrenamiento y prueba. La variable objetivo es Class, que indica si un archivo es malicioso (1) o benigno (0).\nPLANNING: - INTRO - short dataset description. - EDA - shape, dtypes, missing, class balance, sample rows, correlations. - PREPARING DATA - drop useless columns, fix dtype issues, parse timestamps, coerce numerics, encode label. - DATA SPLITTING - splitting training and testing data. - RESULTS - early results. - PREPARING MODELS - prepare hyperparameter, baseline models. - RESULTS WITH MULTIPLES MODELS- metrics (precision/recall/f1), confusion matrix. - BALANCING - try balancing and compare. - RESULTS (after balancing) - compare metrics. - CONCLUSION - state best model, tradeoffs, next steps."
  },
  {
    "objectID": "classification/classification_ransomware.html#importamos-las-librer√≠as-necesarias-y-cargamos-el-dataset",
    "href": "classification/classification_ransomware.html#importamos-las-librer√≠as-necesarias-y-cargamos-el-dataset",
    "title": "Ransomware detection",
    "section": "Importamos las librer√≠as necesarias y cargamos el dataset",
    "text": "Importamos las librer√≠as necesarias y cargamos el dataset\n\nimport pandas as pd\nfrom pathlib import Path\n\nbase_dir = Path.cwd()\ncsv_file_path = base_dir.parent.parent / \"data\" / \"raw_data\" / \"ransom.csv\"\ndata = pd.read_csv(csv_file_path, low_memory=False, index_col=0)\n# Para hacer m√°s r√°pido el procesamiento, tomamos una muestra del dataset\ndf = data.sample(n=1000, random_state=42)\ndf.head(1)\n\n\n\n\n\n\n\n\nsha1\nfile_extension\nEntryPoint\nPEType\nMachineType\nmagic_number\nbytes_on_last_page\npages_in_file\nrelocations\nsize_of_header\n...\ntotal_procsses\nfiles_malicious\nfiles_suspicious\nfiles_text\nfiles_unknown\ndlls_calls\napis\nClass\nCategory\nFamily\n\n\nmd5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8742c015240d3807cda31988658f2b80\n7e89a31bbcbc780f3e2adc777995501f86079d6e\nexe\n0x34a4\nPE32\nIntel 386 or later, and compatibles\nMZ\n0x0090\n0x0003\n0x0004\n0x0000\n...\n36.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nBenign\nBenign\nBenign\n\n\n\n\n1 rows √ó 76 columns"
  },
  {
    "objectID": "classification/classification_ransomware.html#realizamos-un-analisis-exploratorio-sobre-los-datos",
    "href": "classification/classification_ransomware.html#realizamos-un-analisis-exploratorio-sobre-los-datos",
    "title": "Ransomware detection",
    "section": "Realizamos un analisis exploratorio sobre los datos",
    "text": "Realizamos un analisis exploratorio sobre los datos\n\nExploramos la forma general del dataset\n\n# Realizamos un analysis exploratorio sobre los datos\nprint(\"Shape:\", df.shape)\nprint(\"\\nColumns and dtypes:\")\nprint(df.dtypes)\nprint(\"\\nNumeric summary (describe):\")\ndisplay(df.describe().T)\n\nShape: (1000, 76)\n\nColumns and dtypes:\nsha1               object\nfile_extension     object\nEntryPoint         object\nPEType             object\nMachineType        object\n                   ...   \ndlls_calls        float64\napis              float64\nClass              object\nCategory           object\nFamily             object\nLength: 76, dtype: object\n\nNumeric summary (describe):\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nregistry_read\n1000.0\n1969.901\n12792.143237\n0.0\n23.00\n213.5\n898.25\n359646.0\n\n\nregistry_write\n1000.0\n15.826\n84.838194\n0.0\n0.00\n0.0\n3.00\n1448.0\n\n\nregistry_delete\n1000.0\n1.908\n18.058284\n0.0\n0.00\n0.0\n0.00\n298.0\n\n\nregistry_total\n1000.0\n2063.848\n13027.855054\n0.0\n22.75\n221.0\n918.75\n365999.0\n\n\nnetwork_threats\n1000.0\n0.000\n0.000000\n0.0\n0.00\n0.0\n0.00\n0.0\n\n\nnetwork_dns\n1000.0\n4.134\n27.120538\n0.0\n0.00\n0.0\n1.00\n568.0\n\n\nnetwork_http\n1000.0\n1.675\n13.845543\n0.0\n0.00\n0.0\n0.00\n318.0\n\n\nnetwork_connections\n1000.0\n21.927\n174.432217\n0.0\n0.00\n2.0\n5.00\n2192.0\n\n\nprocesses_malicious\n1000.0\n1.835\n10.217151\n0.0\n0.00\n1.0\n2.00\n314.0\n\n\nprocesses_suspicious\n1000.0\n0.359\n2.548846\n0.0\n0.00\n0.0\n0.00\n70.0\n\n\nprocesses_monitored\n1000.0\n9.437\n54.572192\n0.0\n1.00\n2.0\n5.00\n1605.0\n\n\ntotal_procsses\n1000.0\n42.929\n58.420929\n0.0\n34.00\n37.0\n43.00\n1643.0\n\n\nfiles_malicious\n1000.0\n5.892\n30.643815\n0.0\n0.00\n0.0\n1.00\n551.0\n\n\nfiles_suspicious\n1000.0\n359.543\n2003.727509\n0.0\n0.00\n0.0\n4.00\n34060.0\n\n\nfiles_text\n1000.0\n71.734\n331.357745\n0.0\n0.00\n0.0\n3.00\n5947.0\n\n\nfiles_unknown\n1000.0\n23.166\n167.367082\n0.0\n0.00\n0.0\n0.00\n4415.0\n\n\ndlls_calls\n1000.0\n4.591\n5.780236\n0.0\n1.00\n2.0\n7.00\n50.0\n\n\napis\n1000.0\n91.538\n138.579663\n0.0\n1.00\n23.0\n127.00\n953.0\n\n\n\n\n\n\n\n\n\nVerificamos valores nulos\n\n# Resumen de valores nulos\n\nmissing_counts = df.isna().sum()\nmissing_percent = 100 * missing_counts / len(df)\nmissing_summary = pd.concat([missing_counts, missing_percent], axis=1)\nmissing_summary.columns = [\"nulos\", \"porcentaje\"]\nprint(\"\\nNulos por columna (n y %):\")\ndisplay(missing_summary.sort_values(\"nulos\", ascending=False).head(20))\n\n\nNulos por columna (n y %):\n\n\n\n\n\n\n\n\n\nnulos\nporcentaje\n\n\n\n\nsha1\n0\n0.0\n\n\nfile_extension\n0\n0.0\n\n\nEntryPoint\n0\n0.0\n\n\nPEType\n0\n0.0\n\n\nMachineType\n0\n0.0\n\n\nmagic_number\n0\n0.0\n\n\nbytes_on_last_page\n0\n0.0\n\n\npages_in_file\n0\n0.0\n\n\nrelocations\n0\n0.0\n\n\nsize_of_header\n0\n0.0\n\n\nmin_extra_paragraphs\n0\n0.0\n\n\nmax_extra_paragraphs\n0\n0.0\n\n\ninit_ss_value\n0\n0.0\n\n\ninit_sp_value\n0\n0.0\n\n\ninit_ip_value\n0\n0.0\n\n\ninit_cs_value\n0\n0.0\n\n\nover_lay_number\n0\n0.0\n\n\noem_identifier\n0\n0.0\n\n\naddress_of_ne_header\n0\n0.0\n\n\nMagic\n0\n0.0\n\n\n\n\n\n\n\nRevisamos su distribution\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ntarget_col = \"Class\"\nfigsize = (6, 4)\n\n# Muestra los conteos y porcentajes para la variable binaria objetivo\n\nvc = df[target_col].value_counts(dropna=False)\npct = (vc / len(df) * 100).round(2)\nprint(\"Counts:\")\nprint(vc)\nprint(\"\\nPercent:\")\nprint(pct)\n\nplt.figure(figsize=figsize)\nsns.barplot(x=vc.index.astype(str), y=vc.values)\nplt.title(f\"Target distribution: {target_col}\")\nplt.ylabel(\"count\")\nplt.xlabel(target_col)\nplt.show()\n\nCounts:\nClass\nMalware    504\nBenign     496\nName: count, dtype: int64\n\nPercent:\nClass\nMalware    50.4\nBenign     49.6\nName: count, dtype: float64"
  },
  {
    "objectID": "sesion2/1_s2_parte_1.html",
    "href": "sesion2/1_s2_parte_1.html",
    "title": "bootcamp-dci",
    "section": "",
    "text": "En este caso analizamos una funcionalidad de clasificaci√≥n de im√°genes que utiliza un modelo entrenado en Teachable Machine y procesa video capturado desde la c√°mara. El objetivo no es entrenar el modelo, sino comprender c√≥mo una aplicaci√≥n de software integra un modelo ya existente y utiliza sus predicciones.\nLa funcionalidad recibe im√°genes de manera continua desde la c√°mara del dispositivo, ejecuta una clasificaci√≥n sobre cada frame y muestra el resultado directamente en la interfaz de la aplicaci√≥n.",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 1 ‚Äì Clasificaci√≥n de im√°genes usando un modelo entrenado en Teachable Machine"
    ]
  },
  {
    "objectID": "sesion2/1_s2_parte_1.html#caso-1-clasificaci√≥n-de-im√°genes-usando-un-modelo-entrenado-en-teachable-machine",
    "href": "sesion2/1_s2_parte_1.html#caso-1-clasificaci√≥n-de-im√°genes-usando-un-modelo-entrenado-en-teachable-machine",
    "title": "bootcamp-dci",
    "section": "",
    "text": "En este caso analizamos una funcionalidad de clasificaci√≥n de im√°genes que utiliza un modelo entrenado en Teachable Machine y procesa video capturado desde la c√°mara. El objetivo no es entrenar el modelo, sino comprender c√≥mo una aplicaci√≥n de software integra un modelo ya existente y utiliza sus predicciones.\nLa funcionalidad recibe im√°genes de manera continua desde la c√°mara del dispositivo, ejecuta una clasificaci√≥n sobre cada frame y muestra el resultado directamente en la interfaz de la aplicaci√≥n.",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 1 ‚Äì Clasificaci√≥n de im√°genes usando un modelo entrenado en Teachable Machine"
    ]
  },
  {
    "objectID": "sesion2/1_s2_parte_1.html#ejemplo-base",
    "href": "sesion2/1_s2_parte_1.html#ejemplo-base",
    "title": "bootcamp-dci",
    "section": "Ejemplo base",
    "text": "Ejemplo base\nüëâ Ejemplo de clasificaci√≥n con Teachable Machine\nEste ejemplo muestra una aplicaci√≥n web que:\n\naccede a la c√°mara del dispositivo,\nclasifica el video en tiempo real,\ny visualiza la etiqueta detectada junto con un indicador gr√°fico.",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 1 ‚Äì Clasificaci√≥n de im√°genes usando un modelo entrenado en Teachable Machine"
    ]
  },
  {
    "objectID": "sesion2/1_s2_parte_1.html#trabajo-local",
    "href": "sesion2/1_s2_parte_1.html#trabajo-local",
    "title": "bootcamp-dci",
    "section": "Trabajo local",
    "text": "Trabajo local\nPara trabajar este caso durante la sesi√≥n, se utiliza una versi√≥n local del ejemplo.\nSe entrega un archivo comprimido (.zip) que contiene los archivos necesarios para ejecutar la funcionalidad de manera local. Algunos archivos adicionales est√°n incluidos √∫nicamente para asegurar compatibilidad con el entorno de ejecuci√≥n y no requieren modificaciones durante la sesi√≥n.\nAbre la carpeta en Visual Studio Code y ejecuta Go Live para iniciar el servidor local y abrir la aplicaci√≥n en el navegador.\n\n\n\n\n\n\nAdvertencia\n\n\n\nLa versi√≥n web del ejemplo est√° adaptada al framework Quarto, utilizado para la documentaci√≥n del curso.\nEsa adaptaci√≥n modifica la estructura del c√≥digo y no es adecuada para ejecuci√≥n local. Para este caso, trabaja exclusivamente con la versi√≥n incluida en el archivo .zip.\n\n\nüëâ Descargar c√≥digo del Caso 1",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 1 ‚Äì Clasificaci√≥n de im√°genes usando un modelo entrenado en Teachable Machine"
    ]
  },
  {
    "objectID": "sesion2/1_s2_parte_1.html#funcionamiento-general",
    "href": "sesion2/1_s2_parte_1.html#funcionamiento-general",
    "title": "bootcamp-dci",
    "section": "Funcionamiento general",
    "text": "Funcionamiento general\nDesde el punto de vista del software, la funcionalidad implementa el siguiente flujo:\n\nla aplicaci√≥n inicializa el acceso a la c√°mara,\ncada frame del video se entrega al modelo de clasificaci√≥n,\nel modelo produce una etiqueta como salida,\nla aplicaci√≥n actualiza la interfaz con el resultado.\n\n\n\n\n\n\n\nTip\n\n\n\nEl modelo se comporta como un componente externo: la aplicaci√≥n no conoce c√≥mo fue entrenado ni c√≥mo toma decisiones, solo consume su salida.",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 1 ‚Äì Clasificaci√≥n de im√°genes usando un modelo entrenado en Teachable Machine"
    ]
  },
  {
    "objectID": "sesion2/1_s2_parte_1.html#en-qu√©-nos-fijamos-durante-el-an√°lisis",
    "href": "sesion2/1_s2_parte_1.html#en-qu√©-nos-fijamos-durante-el-an√°lisis",
    "title": "bootcamp-dci",
    "section": "En qu√© nos fijamos durante el an√°lisis",
    "text": "En qu√© nos fijamos durante el an√°lisis\nDurante el trabajo con este caso, nos enfocamos en observar:\n\nc√≥mo se integra un modelo entrenado externamente en una aplicaci√≥n de software,\nc√≥mo se gestionan entradas continuas de datos (video),\nc√≥mo se encadena la clasificaci√≥n de m√∫ltiples frames,\nc√≥mo se representa el resultado del modelo en la interfaz.\n\nEl foco est√° en el dise√±o de la funcionalidad, no en la precisi√≥n del modelo ni en la calidad de las predicciones.",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 1 ‚Äì Clasificaci√≥n de im√°genes usando un modelo entrenado en Teachable Machine"
    ]
  },
  {
    "objectID": "sesion2/1_s2_parte_1.html#relaci√≥n-con-la-sesi√≥n",
    "href": "sesion2/1_s2_parte_1.html#relaci√≥n-con-la-sesi√≥n",
    "title": "bootcamp-dci",
    "section": "Relaci√≥n con la sesi√≥n",
    "text": "Relaci√≥n con la sesi√≥n\nEste caso sirve como punto de partida para entender una funcionalidad de clasificaci√≥n basada en un modelo espec√≠fico y entrenado para un contexto concreto. En el siguiente caso se analizar√° un enfoque distinto, utilizando un modelo preentrenado y una entrada de datos diferente, lo que permitir√° contrastar decisiones de dise√±o.",
    "crumbs": [
      "Sesi√≥n 2",
      "Caso 1 ‚Äì Clasificaci√≥n de im√°genes usando un modelo entrenado en Teachable Machine"
    ]
  },
  {
    "objectID": "sesion1/1_parte_1.html",
    "href": "sesion1/1_parte_1.html",
    "title": "bootcamp-dci",
    "section": "",
    "text": "TipIdea clave\n\n\n\nComprender el problema de la predicci√≥n es el primer paso para entender cualquier funcionalidad de software basada en inteligencia artificial, incluida la clasificaci√≥n de im√°genes. Antes de hablar de modelos, librer√≠as o implementaci√≥n, es fundamental aclarar qu√© significa que un sistema ‚Äúprediga‚Äù algo.\n\n\nEn el contexto del software, una predicci√≥n puede entenderse como:\n\nUn resultado producido por el sistema a partir de datos de entrada\nUn resultado basado en patrones aprendidos previamente\nUna estimaci√≥n, no una certeza absoluta\n\nEl sistema no razona ni interpreta el mundo como una persona. Su comportamiento se limita a procesar datos y generar una salida siguiendo relaciones establecidas a partir de datos anteriores.\nEsta idea suele ser dif√≠cil de comprender al comienzo, porque tendemos a atribuirle al sistema una forma de razonamiento similar a la humana. Una analog√≠a √∫til es pensar en una persona que aprende por repetici√≥n, no por comprensi√≥n expl√≠cita.\nPor ejemplo, imagina a alguien que nunca ha estudiado meteorolog√≠a, pero que durante a√±os ha observado el clima todos los d√≠as. Esa persona no sabe explicar cient√≠ficamente por qu√© llueve ni c√≥mo funcionan los fen√≥menos atmos√©ricos, pero despu√©s de ver muchas veces el cielo, la temperatura y el viento, es capaz de decir ‚Äúhoy probablemente va a llover‚Äù. Esa predicci√≥n no se basa en entender el fen√≥meno, sino en reconocer patrones que ha visto antes.\nUn sistema de software basado en inteligencia artificial funciona de manera muy similar. No entiende qu√© es la lluvia, el calor o el buen tiempo. Lo √∫nico que hace es observar datos, identificar regularidades y, cuando recibe un nuevo conjunto de datos, producir un resultado que se parece a los casos anteriores. La predicci√≥n es, por tanto, una respuesta basada en experiencia acumulada, no en comprensi√≥n del mundo.\nEsta analog√≠a ayuda a aclarar por qu√© una predicci√≥n no es una certeza y por qu√© el sistema puede equivocarse incluso cuando ‚Äúparece‚Äù estar seguro. El sistema no razona ni explica; simplemente elige la salida que m√°s se parece a lo que ha visto antes.\nA partir de esta definici√≥n general, es importante entender que existen dos tipos b√°sicos de predicciones que aparecen de forma recurrente en sistemas de software:\n\nRegresi√≥n\nClasificaci√≥n\n\nDistinguir entre ambos tipos es clave para entender qu√© tipo de problema resuelve la clasificaci√≥n de im√°genes.",
    "crumbs": [
      "Sesi√≥n 1",
      "üîÆ El problema de la predicci√≥n"
    ]
  },
  {
    "objectID": "sesion1/1_parte_1.html#el-problema-de-la-predicci√≥n",
    "href": "sesion1/1_parte_1.html#el-problema-de-la-predicci√≥n",
    "title": "bootcamp-dci",
    "section": "",
    "text": "TipIdea clave\n\n\n\nComprender el problema de la predicci√≥n es el primer paso para entender cualquier funcionalidad de software basada en inteligencia artificial, incluida la clasificaci√≥n de im√°genes. Antes de hablar de modelos, librer√≠as o implementaci√≥n, es fundamental aclarar qu√© significa que un sistema ‚Äúprediga‚Äù algo.\n\n\nEn el contexto del software, una predicci√≥n puede entenderse como:\n\nUn resultado producido por el sistema a partir de datos de entrada\nUn resultado basado en patrones aprendidos previamente\nUna estimaci√≥n, no una certeza absoluta\n\nEl sistema no razona ni interpreta el mundo como una persona. Su comportamiento se limita a procesar datos y generar una salida siguiendo relaciones establecidas a partir de datos anteriores.\nEsta idea suele ser dif√≠cil de comprender al comienzo, porque tendemos a atribuirle al sistema una forma de razonamiento similar a la humana. Una analog√≠a √∫til es pensar en una persona que aprende por repetici√≥n, no por comprensi√≥n expl√≠cita.\nPor ejemplo, imagina a alguien que nunca ha estudiado meteorolog√≠a, pero que durante a√±os ha observado el clima todos los d√≠as. Esa persona no sabe explicar cient√≠ficamente por qu√© llueve ni c√≥mo funcionan los fen√≥menos atmos√©ricos, pero despu√©s de ver muchas veces el cielo, la temperatura y el viento, es capaz de decir ‚Äúhoy probablemente va a llover‚Äù. Esa predicci√≥n no se basa en entender el fen√≥meno, sino en reconocer patrones que ha visto antes.\nUn sistema de software basado en inteligencia artificial funciona de manera muy similar. No entiende qu√© es la lluvia, el calor o el buen tiempo. Lo √∫nico que hace es observar datos, identificar regularidades y, cuando recibe un nuevo conjunto de datos, producir un resultado que se parece a los casos anteriores. La predicci√≥n es, por tanto, una respuesta basada en experiencia acumulada, no en comprensi√≥n del mundo.\nEsta analog√≠a ayuda a aclarar por qu√© una predicci√≥n no es una certeza y por qu√© el sistema puede equivocarse incluso cuando ‚Äúparece‚Äù estar seguro. El sistema no razona ni explica; simplemente elige la salida que m√°s se parece a lo que ha visto antes.\nA partir de esta definici√≥n general, es importante entender que existen dos tipos b√°sicos de predicciones que aparecen de forma recurrente en sistemas de software:\n\nRegresi√≥n\nClasificaci√≥n\n\nDistinguir entre ambos tipos es clave para entender qu√© tipo de problema resuelve la clasificaci√≥n de im√°genes.",
    "crumbs": [
      "Sesi√≥n 1",
      "üîÆ El problema de la predicci√≥n"
    ]
  },
  {
    "objectID": "sesion1/1_parte_1.html#regresi√≥n-y-clasificaci√≥n",
    "href": "sesion1/1_parte_1.html#regresi√≥n-y-clasificaci√≥n",
    "title": "bootcamp-dci",
    "section": "üìà Regresi√≥n y clasificaci√≥n",
    "text": "üìà Regresi√≥n y clasificaci√≥n\nLa siguiente figura ilustra la diferencia entre ambos tipos de predicci√≥n utilizando los ejemplos discutidos en el texto.\n\n\n\n\n\nLa regresi√≥n corresponde a predicciones cuyo resultado es un valor num√©rico continuo. Un ejemplo cl√°sico es la predicci√≥n de temperatura.\nLa siguiente tabla muestra un conjunto simplificado de datos de entrada y el valor que se desea predecir:\n\n\n\n\n\n\n\n\n\n\nD√≠a\nTemperatura ma√±ana (¬∞C)\nHumedad (%)\nNubosidad\nTemperatura tarde (¬∞C)\n\n\n\n\n1\n14.0\n80\nAlta\n18.5\n\n\n2\n16.5\n65\nMedia\n22.0\n\n\n3\n18.0\n55\nBaja\n25.3\n\n\n\nEn este caso:\n\nLas columnas de la izquierda corresponden a datos de entrada\nLa √∫ltima columna es el valor num√©rico que se quiere predecir\nEl resultado es un n√∫mero continuo dentro de un rango posible\n\nEl n√∫mero exacto puede variar, pero siempre representa una magnitud medible.\nLa clasificaci√≥n, en cambio, corresponde a predicciones cuyo resultado es una categor√≠a. Un ejemplo simple es la predicci√≥n del estado del tiempo en t√©rminos como ‚Äúbueno‚Äù o ‚Äúmalo‚Äù.\nLa siguiente tabla ilustra este tipo de problema:\n\n\n\nD√≠a\nTemperatura (¬∞C)\nHumedad (%)\nViento\nEstado del tiempo\n\n\n\n\n1\n18\n70\nBajo\nBueno\n\n\n2\n15\n85\nAlto\nMalo\n\n\n3\n22\n60\nBajo\nBueno\n\n\n\nEn este caso:\n\nLos datos de entrada siguen siendo valores medibles\nLa salida no es un n√∫mero\nEl sistema debe elegir una clase entre un conjunto finito de opciones\n\nEsta distinci√≥n es fundamental, porque la clasificaci√≥n de im√°genes pertenece claramente a este segundo tipo. Cuando un sistema clasifica una imagen:\n\nNo mide algo continuo\nNo produce un valor num√©rico como salida principal\nDecide a qu√© clase pertenece la imagen\n\nPor ejemplo, una tabla conceptual para clasificaci√≥n de im√°genes podr√≠a verse as√≠:\n\n\n\nImagen\nCaracter√≠sticas extra√≠das\nClase asignada\n\n\n\n\nImagen 1\nBordes, colores, formas\nGato\n\n\nImagen 2\nBordes, texturas\nPerro\n\n\nImagen 3\nSombras, contornos\nAve\n\n\n\nOtro aspecto importante es entender que, tanto en regresi√≥n como en clasificaci√≥n, una predicci√≥n no es una verdad absoluta. El sistema no ‚Äúsabe‚Äù cu√°l es la respuesta correcta. Lo que hace es:\n\nEstimar el resultado m√°s probable\nBasarse en los datos disponibles\nUtilizar patrones aprendidos previamente\n\nPor esta raz√≥n, una predicci√≥n siempre puede ser incorrecta.\nEste punto es especialmente relevante cuando se trabaja con im√°genes. Para una persona, una imagen puede representar claramente un objeto o una situaci√≥n. Para el computador, en cambio:\n\nUna imagen es solo un conjunto de datos num√©ricos\nNo existe una comprensi√≥n visual en el sentido humano\nLa predicci√≥n se basa en similitudes con ejemplos vistos anteriormente\n\nEn esta parte de la sesi√≥n, el objetivo es que los estudiantes comprendan que la predicci√≥n es el problema central que se intenta resolver, y que existen distintos tipos de predicci√≥n con objetivos distintos. La clasificaci√≥n de im√°genes es un caso particular de predicci√≥n por clasificaci√≥n, y entender esta diferencia es esencial antes de avanzar hacia la implementaci√≥n de un clasificador.\nEsta comprensi√≥n servir√° como base directa para la siguiente parte, donde se abordar√° qu√© significa implementar un clasificador como una funcionalidad concreta dentro de un sistema de software.",
    "crumbs": [
      "Sesi√≥n 1",
      "üîÆ El problema de la predicci√≥n"
    ]
  },
  {
    "objectID": "sesion1/3_parte_3.html",
    "href": "sesion1/3_parte_3.html",
    "title": "bootcamp-dci",
    "section": "",
    "text": "TipIdea clave\n\n\n\nAnalizar c√≥mo se hacen predicciones usando el clasificador es el tercer paso para comprender una funcionalidad de clasificaci√≥n de im√°genes como parte de un sistema de software. En esta etapa, el foco est√° en observar qu√© ocurre cuando el clasificador ya est√° implementado y recibe nuevos datos como entrada.\n\n\nPara este an√°lisis se utilizar√° un clasificador de im√°genes que ya forma parte del repositorio del curso, ubicado en el siguiente enlace:\nhttps://dci-courses.github.io/bootcamp-dci/ml5/image_classification.html\nEl objetivo aqu√≠ no es estudiar su implementaci√≥n interna, sino observar su comportamiento desde el punto de vista de la funcionalidad completa.\n\n\nUna vez que el clasificador existe, el sistema puede recibir una imagen nueva, es decir, una imagen que no form√≥ parte de los ejemplos utilizados para construir el clasificador.\nCuando esto ocurre, el sistema:\n\nRecibe la imagen como dato de entrada\nLa procesa internamente como datos num√©ricos\nLa compara con los patrones aprendidos previamente\nProduce una predicci√≥n categ√≥rica\n\nLa predicci√≥n corresponde a la clase que el sistema considera m√°s similar a la imagen de entrada.\n\n\n\nEl clasificador no analiza la imagen como lo har√≠a una persona. En lugar de eso:\n\nNo identifica objetos ni significados\nNo ‚Äúentiende‚Äù el contenido visual\nSolo eval√∫a similitudes con ejemplos anteriores\n\nEl resultado es una decisi√≥n que indica a qu√© clase pertenece la imagen, seg√∫n los patrones aprendidos durante la construcci√≥n del clasificador.\nEn muchos casos, el sistema tambi√©n muestra informaci√≥n adicional asociada a la predicci√≥n, como el grado de confianza, lo que refuerza la idea de que la decisi√≥n es el resultado de una comparaci√≥n entre varias posibilidades.\n\n\n\nUn aspecto clave de esta parte es entender que la predicci√≥n no es una verdad absoluta. El sistema:\n\nNo sabe cu√°l es la respuesta correcta\nNo puede garantizar que su decisi√≥n sea correcta\nProduce una estimaci√≥n basada en experiencia previa\n\nPor esta raz√≥n, el clasificador puede equivocarse, incluso cuando parece estar seguro de su predicci√≥n.\n\n\n\nAl analizar las predicciones producidas por el clasificador, es importante tener en cuenta que:\n\nEl resultado depende de las clases definidas\nEl resultado depende de los ejemplos utilizados\nCambios en estos elementos pueden cambiar la predicci√≥n\n\nEsto permite entender por qu√© una misma imagen puede recibir predicciones distintas en contextos diferentes y refuerza la idea de que la predicci√≥n es una salida probabil√≠stica, no una afirmaci√≥n definitiva sobre el contenido de la imagen.",
    "crumbs": [
      "Sesi√≥n 1",
      "üìä Analizar c√≥mo se hacen predicciones usando el clasificador"
    ]
  },
  {
    "objectID": "sesion1/3_parte_3.html#analizar-c√≥mo-se-hacen-predicciones-usando-el-clasificador",
    "href": "sesion1/3_parte_3.html#analizar-c√≥mo-se-hacen-predicciones-usando-el-clasificador",
    "title": "bootcamp-dci",
    "section": "",
    "text": "TipIdea clave\n\n\n\nAnalizar c√≥mo se hacen predicciones usando el clasificador es el tercer paso para comprender una funcionalidad de clasificaci√≥n de im√°genes como parte de un sistema de software. En esta etapa, el foco est√° en observar qu√© ocurre cuando el clasificador ya est√° implementado y recibe nuevos datos como entrada.\n\n\nPara este an√°lisis se utilizar√° un clasificador de im√°genes que ya forma parte del repositorio del curso, ubicado en el siguiente enlace:\nhttps://dci-courses.github.io/bootcamp-dci/ml5/image_classification.html\nEl objetivo aqu√≠ no es estudiar su implementaci√≥n interna, sino observar su comportamiento desde el punto de vista de la funcionalidad completa.\n\n\nUna vez que el clasificador existe, el sistema puede recibir una imagen nueva, es decir, una imagen que no form√≥ parte de los ejemplos utilizados para construir el clasificador.\nCuando esto ocurre, el sistema:\n\nRecibe la imagen como dato de entrada\nLa procesa internamente como datos num√©ricos\nLa compara con los patrones aprendidos previamente\nProduce una predicci√≥n categ√≥rica\n\nLa predicci√≥n corresponde a la clase que el sistema considera m√°s similar a la imagen de entrada.\n\n\n\nEl clasificador no analiza la imagen como lo har√≠a una persona. En lugar de eso:\n\nNo identifica objetos ni significados\nNo ‚Äúentiende‚Äù el contenido visual\nSolo eval√∫a similitudes con ejemplos anteriores\n\nEl resultado es una decisi√≥n que indica a qu√© clase pertenece la imagen, seg√∫n los patrones aprendidos durante la construcci√≥n del clasificador.\nEn muchos casos, el sistema tambi√©n muestra informaci√≥n adicional asociada a la predicci√≥n, como el grado de confianza, lo que refuerza la idea de que la decisi√≥n es el resultado de una comparaci√≥n entre varias posibilidades.\n\n\n\nUn aspecto clave de esta parte es entender que la predicci√≥n no es una verdad absoluta. El sistema:\n\nNo sabe cu√°l es la respuesta correcta\nNo puede garantizar que su decisi√≥n sea correcta\nProduce una estimaci√≥n basada en experiencia previa\n\nPor esta raz√≥n, el clasificador puede equivocarse, incluso cuando parece estar seguro de su predicci√≥n.\n\n\n\nAl analizar las predicciones producidas por el clasificador, es importante tener en cuenta que:\n\nEl resultado depende de las clases definidas\nEl resultado depende de los ejemplos utilizados\nCambios en estos elementos pueden cambiar la predicci√≥n\n\nEsto permite entender por qu√© una misma imagen puede recibir predicciones distintas en contextos diferentes y refuerza la idea de que la predicci√≥n es una salida probabil√≠stica, no una afirmaci√≥n definitiva sobre el contenido de la imagen.",
    "crumbs": [
      "Sesi√≥n 1",
      "üìä Analizar c√≥mo se hacen predicciones usando el clasificador"
    ]
  },
  {
    "objectID": "ml5/image_classification_tm.html",
    "href": "ml5/image_classification_tm.html",
    "title": "Clasificador de Video con Teachable Machine",
    "section": "",
    "text": "Este modelo utiliza un clasificador entrenado en Teachable Machine para analizar im√°genes capturadas desde una c√°mara web en tiempo real. El clasificador puede identificar patrones visuales definidos durante el entrenamiento del modelo y producir una predicci√≥n continua a partir del video.\nInstrucciones:",
    "crumbs": [
      "Ejemplos",
      "Clasificador de Video con Teachable Machine"
    ]
  },
  {
    "objectID": "ml5/image_classification_tm.html#explicaci√≥n-del-c√≥digo",
    "href": "ml5/image_classification_tm.html#explicaci√≥n-del-c√≥digo",
    "title": "Clasificador de Video con Teachable Machine",
    "section": "Explicaci√≥n del C√≥digo",
    "text": "Explicaci√≥n del C√≥digo\n\nC√≥digo Completo\n// Clasificador de im√°genes cargado desde Teachable Machine\nlet classifier;\n\n// Video capturado en tiempo real desde la c√°mara web\nlet video;\n\n// Etiqueta resultante de la clasificaci√≥n\nlet label = \"\";\n\n// URL del modelo entrenado en Teachable Machine\nconst modelURL = \"https://teachablemachine.withgoogle.com/models/bXy2kDNi/\";\n\n// Se ejecuta antes de setup() y se usa para cargar recursos\nfunction preload() {\n    // Cargar el modelo de clasificaci√≥n entrenado previamente\n    classifier = ml5.imageClassifier(modelURL);\n}\n\nfunction setup() {\n    // Crear el lienzo donde se mostrar√° el video\n    createCanvas(640, 520);\n\n    // Activar la c√°mara y capturar el video\n    video = createCapture(VIDEO);\n\n    // Ocultar el elemento HTML del video (solo se usa el canvas)\n    video.hide();\n\n    // Iniciar la primera clasificaci√≥n del video\n    classifier.classify(video, gotResult);\n}\n\n// Funci√≥n callback que se ejecuta cuando el modelo entrega un resultado\nfunction gotResult(error, results) {\n    // Verificar si ocurri√≥ un error durante la clasificaci√≥n\n    if (error) {\n        console.error(error);\n        return;\n    }\n\n    // Guardar la etiqueta m√°s probable\n    label = results[0].label;\n\n    // Volver a clasificar el siguiente frame del video\n    classifier.classify(video, gotResult);\n}\n\nfunction draw() {\n    // Dibujar el video en el lienzo\n    image(video, 0, 0, width, height);\n\n    // Configurar el estilo del texto\n    fill(255);\n    stroke(0);\n    strokeWeight(2);\n    textSize(18);\n\n    // Mostrar la etiqueta detectada en pantalla\n    text(\"Etiqueta: \" + label, 10, height - 20);\n}\n\n\n1. Declaraci√≥n de Variables\nPrimero, declaramos las variables que necesitaremos durante todo el proceso:\n// Clasificador de im√°genes cargado desde Teachable Machine\nlet classifier;\n\n// Video capturado en tiempo real desde la c√°mara web\nlet video;\n\n// Etiqueta resultante de la clasificaci√≥n\nlet label = \"\";\n\n// URL del modelo entrenado en Teachable Machine\nconst modelURL = \"https://teachablemachine.withgoogle.com/models/bXy2kDNi/\";\n\n\n2. Carga del Modelo (preload)\nLa funci√≥n preload() se ejecuta antes de setup() y es ideal para cargar recursos:\nfunction preload() {\n    classifier = ml5.imageClassifier(modelURL);\n}\n\n\n3. Configuraci√≥n Inicial (setup)\nLa funci√≥n setup() se ejecuta una vez al inicio:\nfunction setup() {\n    createCanvas(640, 520);\n    video = createCapture(VIDEO);\n    video.hide();\n    classifier.classify(video, gotResult);\n}\n\n\n4. Procesamiento de Resultados\nLa funci√≥n gotResult es un callback que recibe los resultados de la clasificaci√≥n:\nfunction gotResult(error, results) {\n    if (error) {\n        console.error(error);\n        return;\n    }\n    label = results[0].label;\n    classifier.classify(video, gotResult);\n}\n\n\n5. Visualizaci√≥n del Resultado (draw)\nLa funci√≥n draw() se ejecuta varias veces por segundo:\nfunction draw() {\n    image(video, 0, 0, width, height);\n    fill(255);\n    stroke(0);\n    strokeWeight(2);\n    textSize(18);\n    text(\"Etiqueta: \" + label, 10, height - 20);\n}",
    "crumbs": [
      "Ejemplos",
      "Clasificador de Video con Teachable Machine"
    ]
  },
  {
    "objectID": "ml5/dino_run.html",
    "href": "ml5/dino_run.html",
    "title": "Dino Run - Control por Gestos",
    "section": "",
    "text": "Este es un juego de dinosaurio corredor donde debes saltar sobre los obst√°culos. En lugar de usar el teclado, el juego se controla mediante gestos capturados por tu c√°mara web usando un modelo de Teachable Machine.\nInstrucciones:",
    "crumbs": [
      "Ejemplos",
      "Dino Run - Control por Gestos"
    ]
  },
  {
    "objectID": "ml5/dino_run.html#c√≥digo-completo",
    "href": "ml5/dino_run.html#c√≥digo-completo",
    "title": "Dino Run - Control por Gestos",
    "section": "C√≥digo Completo",
    "text": "C√≥digo Completo\n// Game objects\nlet dino;\nlet obstacles = [];\nlet groundY = 300;\n\n// ML5 variables\nlet classifier;\nlet video;\nlet movementLabel = '';\n\n// Game variables\nlet count = 0;\nlet gameOver = false;\nlet gameStarted = false;\nlet countdown = 3;\nlet countdownTimer = 0;\nlet lastObstacleFrame = 0;\nlet minObstacleDistance = 80;\n\n// Images\nlet imgDino;\nlet imgTree;\nlet imgExplosion;\n\nfunction preload() {\n    imgDino = loadImage(\"../data/images/dino_run/dino.png\");\n    imgTree = loadImage(\"../data/images/dino_run/tree.png\");\n    imgExplosion = loadImage(\"../data/images/dino_run/explosion.png\");\n    classifier = ml5.imageClassifier('https://teachablemachine.withgoogle.com/models/Ij_wIPp5Q/model.json');\n}\n\nfunction setup() {\n    createCanvas(800, 400);\n    \n    video = createCapture(VIDEO);\n    video.size(160, 120);\n    video.hide();\n    \n    dino = new Dino(groundY);\n    obstacles.push(new Obstacle(groundY));\n    \n    countdownTimer = millis();\n    classifyVideo();\n}\n\nfunction classifyVideo() {\n    if (!gameOver) {\n        classifier.classify(video, gotResults);\n    }\n}\n\nfunction gotResults(error, results) {\n    if (error) {\n        console.error(error);\n        return;\n    }\n    \n    if (results && results.length &gt; 0) {\n        movementLabel = results[0].label;\n    }\n    \n    setModelGesture();\n    classifyVideo();\n}\n\nfunction setModelGesture() {\n    if (movementLabel === 'Jump') {\n        dino.jump();\n    }\n}\n\nfunction draw() {\n    background(220);\n    \n    // Countdown logic\n    if (!gameStarted && !gameOver) {\n        let elapsed = millis() - countdownTimer;\n        countdown = 3 - floor(elapsed / 1000);\n        \n        if (countdown &lt;= 0) {\n            gameStarted = true;\n        }\n    }\n    \n    // Update and draw the dinosaur\n    dino.update();\n    dino.show();\n    \n    // Display score\n    textSize(32);\n    textAlign(LEFT, TOP);\n    fill(0);\n    text(`Points: ${count}`, 10, 10);\n    \n    // Display hit points (hearts)\n    textSize(20);\n    let hearts = '';\n    for (let i = 0; i &lt; dino.getHitPoints(); i++) {\n        hearts += '‚ù§Ô∏è ';\n    }\n    text(`HP: ${hearts}`, 10, 50);\n    \n    // Display gesture\n    textSize(20);\n    text(`Gesture: ${movementLabel}`, 10, 80);\n    \n    // Show countdown\n    if (!gameStarted && !gameOver && countdown &gt; 0) {\n        fill(255, 165, 0);\n        textSize(72);\n        textAlign(CENTER, CENTER);\n        text(countdown, width/2, height/2);\n    }\n    \n    // Spawn obstacles with proper spacing\n    if (gameStarted && !gameOver) {\n        let framesSinceLastObstacle = frameCount - lastObstacleFrame;\n        let randomInterval = random(minObstacleDistance, minObstacleDistance + 40);\n        \n        if (framesSinceLastObstacle &gt;= randomInterval) {\n            obstacles.push(new Obstacle(groundY));\n            lastObstacleFrame = frameCount;\n        }\n    }\n    \n    // Update and draw each obstacle\n    for (let i = obstacles.length - 1; i &gt;= 0; i--) {\n        if (gameStarted) {\n            obstacles[i].update();\n        }\n        obstacles[i].show();\n        \n        // Check collision\n        if (gameStarted && obstacles[i].hits(dino) && !gameOver) {\n            let isGameOver = dino.hit();\n            if (isGameOver) {\n                gameOver = true;\n            }\n            obstacles.splice(i, 1);\n            continue;\n        }\n        \n        // Remove offscreen obstacles\n        if (obstacles[i].offscreen()) {\n            if (gameStarted) {\n                count++;\n            }\n            obstacles.splice(i, 1);\n        }\n    }\n    \n    // Draw the ground line\n    stroke(0);\n    line(0, groundY, width, groundY);\n    \n    // Draw webcam feed in top right corner\n    push();\n    translate(width - 165, 5);\n    stroke(0);\n    strokeWeight(3);\n    fill(255);\n    rect(0, 0, 160, 120);\n    image(video, 0, 0, 160, 120);\n    pop();\n    \n    // Show game over message\n    if (gameOver) {\n        fill(0);\n        textSize(48);\n        textAlign(CENTER, CENTER);\n        text(\"GAME OVER\", width/2, height/2 - 30);\n        textSize(24);\n        text(`Total Points: ${count}`, width/2, height/2 + 20);\n        text(`Total Jumps: ${dino.getTotalJumps()}`, width/2, height/2 + 50);\n    }\n}\n\n// Dino class\nclass Dino {\n    constructor(groundY) {\n        this.r = 50;\n        this.x = 50;\n        this.groundY = groundY;\n        this.y = groundY - this.r;\n        this.vy = 0;\n        this.gravity = 1.5;\n        this.totalJumps = 0;\n        this.isDead = false;\n        this.hitPoints = 3;\n        this.invulnerable = false;\n        this.invulnerableTimer = 0;\n    }\n    \n    jump() {\n        if (this.y === this.groundY - this.r) {\n            this.totalJumps++;\n            this.vy = -28;\n        }\n    }\n    \n    update() {\n        this.y += this.vy;\n        this.vy += this.gravity;\n        \n        if (this.y &gt; this.groundY - this.r) {\n            this.y = this.groundY - this.r;\n            this.vy = 0;\n        }\n        \n        if (this.invulnerable && millis() - this.invulnerableTimer &gt; 2000) {\n            this.invulnerable = false;\n        }\n    }\n    \n    hit() {\n        if (!this.invulnerable && !this.isDead) {\n            this.hitPoints--;\n            if (this.hitPoints &lt;= 0) {\n                this.dead();\n                return true;\n            } else {\n                this.invulnerable = true;\n                this.invulnerableTimer = millis();\n                return false;\n            }\n        }\n        return false;\n    }\n    \n    dead() {\n        this.isDead = true;\n    }\n    \n    show() {\n        if (this.invulnerable && frameCount % 10 &lt; 5) {\n            push();\n            tint(255, 100, 100);\n            if (this.isDead) {\n                image(imgExplosion, this.x, this.y, this.r, this.r);\n            } else {\n                image(imgDino, this.x, this.y, this.r, this.r);\n            }\n            pop();\n        } else {\n            if (this.isDead) {\n                image(imgExplosion, this.x, this.y, this.r, this.r);\n            } else {\n                image(imgDino, this.x, this.y, this.r, this.r);\n            }\n        }\n    }\n    \n    getTotalJumps() {\n        return this.totalJumps;\n    }\n    \n    getHitPoints() {\n        return this.hitPoints;\n    }\n}\n\n// Obstacle class\nclass Obstacle {\n    constructor(groundY) {\n        this.w = 20;\n        this.h = random(40, 80);\n        this.x = width;\n        this.groundY = groundY;\n        this.y = groundY - this.h;\n        this.speed = 3;\n    }\n    \n    update() {\n        this.x -= this.speed;\n    }\n    \n    offscreen() {\n        return this.x &lt; -this.w;\n    }\n    \n    show() {\n        image(imgTree, this.x, this.y, this.w, this.h);\n    }\n    \n    hits(dino) {\n        return (\n            dino.x &lt; this.x + this.w &&\n            dino.x + dino.r &gt; this.x &&\n            dino.y &lt; this.y + this.h &&\n            dino.y + dino.r &gt; this.y\n        );\n    }\n}",
    "crumbs": [
      "Ejemplos",
      "Dino Run - Control por Gestos"
    ]
  },
  {
    "objectID": "ml5/image_classification.html",
    "href": "ml5/image_classification.html",
    "title": "Clasificador de Im√°genes",
    "section": "",
    "text": "Este modelo utiliza MobileNet, una red neuronal convolucional entrenada para clasificar im√°genes en m√°s de 1000 categor√≠as diferentes. El clasificador puede identificar objetos comunes, animales, veh√≠culos, alimentos y mucho m√°s.\nInstrucciones:",
    "crumbs": [
      "Ejemplos",
      "Clasificador de Im√°genes"
    ]
  },
  {
    "objectID": "ml5/image_classification.html#explicaci√≥n-del-c√≥digo",
    "href": "ml5/image_classification.html#explicaci√≥n-del-c√≥digo",
    "title": "Clasificador de Im√°genes",
    "section": "Explicaci√≥n del C√≥digo",
    "text": "Explicaci√≥n del C√≥digo\n\nC√≥digo Completo\n// Initialize the Image Classifier method with MobileNet\nlet classifier;\n\n// A variable to hold the image we want to classify\nlet img;\n\n// Variables for displaying the results on the canvas\nlet label = \"\";\nlet confidence = \"\";\n\n// Array of available images\nconst images = [\n    \"../data/images/image_classification/cheetah.png\",\n    \"../data/images/image_classification/flamingo.png\",\n    \"../data/images/image_classification/lion.png\",\n    \"../data/images/image_classification/panda.png\"\n];\n\nfunction preload() {\n    classifier = ml5.imageClassifier(\"MobileNet\");\n    // Randomly select one image\n    const randomImage = images[Math.floor(Math.random() * images.length)];\n    img = loadImage(randomImage);\n}\n\nfunction setup() {\n    createCanvas(400, 400);\n    \n    // Display the image\n    image(img, 0, 0, width, height);\n    \n    // Classify the image\n    classifier.classify(img, gotResult);\n}\n\n// Callback function for when classification has finished\nfunction gotResult(error, results) {\n    if (error) {\n        console.error(error);\n        return;\n    }\n    \n    // The results are in an array ordered by confidence\n    console.log(results);\n\n    // Display the results on the canvas\n    fill(255);\n    stroke(0);\n    strokeWeight(2);\n    textSize(18);\n    label = \"Etiqueta: \" + results[0].label;\n    confidence = \"Confianza: \" + nf(results[0].confidence, 0, 2);\n    text(label, 10, 360);\n    text(confidence, 10, 380);\n}\n\n\n1. Declaraci√≥n de Variables\nPrimero, declaramos las variables que necesitaremos durante todo el proceso:\nlet classifier;\nlet img;\nlet label = \"\";\nlet confidence = \"\";\n\nclassifier: Almacenar√° el modelo MobileNet de ml5.js\nimg: Guardar√° la imagen que queremos clasificar\nlabel y confidence: Contendr√°n los resultados de la clasificaci√≥n\n\n\n\n2. Array de Im√°genes Disponibles\nDefinimos un array con las rutas de las im√°genes que queremos clasificar:\nconst images = [\n    \"../data/images/image_classification/cheetah.png\",\n    \"../data/images/image_classification/flamingo.png\",\n    \"../data/images/image_classification/lion.png\",\n    \"../data/images/image_classification/panda.png\"\n];\n\n\n3. Carga del Modelo y la Imagen (preload)\nLa funci√≥n preload() se ejecuta antes de setup() y es ideal para cargar recursos:\nfunction preload() {\n    classifier = ml5.imageClassifier(\"MobileNet\");\n    const randomImage = images[Math.floor(Math.random() * images.length)];\n    img = loadImage(randomImage);\n}\n\nml5.imageClassifier(\"MobileNet\"): Carga el modelo pre-entrenado MobileNet\nMath.floor(Math.random() * images.length): Selecciona un √≠ndice aleatorio del array\nloadImage(): Carga la imagen seleccionada\n\n\n\n4. Configuraci√≥n Inicial (setup)\nLa funci√≥n setup() se ejecuta una vez al inicio:\nfunction setup() {\n    createCanvas(400, 400);\n    image(img, 0, 0, width, height);\n    classifier.classify(img, gotResult);\n}\n\ncreateCanvas(400, 400): Crea un lienzo de 400x400 p√≠xeles\nimage(img, 0, 0, width, height): Dibuja la imagen en el canvas\nclassifier.classify(img, gotResult): Inicia la clasificaci√≥n y llama a gotResult cuando termine\n\n\n\n5. Procesamiento de Resultados\nLa funci√≥n gotResult es un callback que recibe los resultados de la clasificaci√≥n:\nfunction gotResult(error, results) {\n    if (error) {\n        console.error(error);\n        return;\n    }\n    \n    console.log(results);\n    \n    fill(255);\n    stroke(0);\n    strokeWeight(2);\n    textSize(18);\n    label = \"Etiqueta: \" + results[0].label;\n    confidence = \"Confianza: \" + nf(results[0].confidence, 0, 2);\n    text(label, 10, 360);\n    text(confidence, 10, 380);\n}\n\nerror: Contiene informaci√≥n si algo sali√≥ mal\nresults: Array ordenado por confianza, donde results[0] es la predicci√≥n m√°s probable\nresults[0].label: La etiqueta de la clasificaci√≥n (ej: ‚Äúpanda‚Äù)\nresults[0].confidence: Nivel de confianza entre 0 y 1\nnf(): Formatea el n√∫mero con 2 decimales",
    "crumbs": [
      "Ejemplos",
      "Clasificador de Im√°genes"
    ]
  },
  {
    "objectID": "sesion3/1_s3_parte_1.html",
    "href": "sesion3/1_s3_parte_1.html",
    "title": "bootcamp-dci",
    "section": "",
    "text": "En esta primera parte de la sesi√≥n se analiza una funcionalidad de software que aborda un problema de predicci√≥n m√°s avanzado que los trabajados en sesiones anteriores, pero que mantiene una estructura conceptual similar.\nEl objetivo no es aprender una nueva t√©cnica, sino entender c√≥mo cambia el problema de predicci√≥n y c√≥mo ese cambio impacta en el comportamiento de la aplicaci√≥n.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 1 ‚Äì Un problema de predicci√≥n m√°s avanzado: detecci√≥n de objetos"
    ]
  },
  {
    "objectID": "sesion3/1_s3_parte_1.html#parte-1-un-problema-de-predicci√≥n-m√°s-avanzado-detecci√≥n-de-objetos",
    "href": "sesion3/1_s3_parte_1.html#parte-1-un-problema-de-predicci√≥n-m√°s-avanzado-detecci√≥n-de-objetos",
    "title": "bootcamp-dci",
    "section": "",
    "text": "En esta primera parte de la sesi√≥n se analiza una funcionalidad de software que aborda un problema de predicci√≥n m√°s avanzado que los trabajados en sesiones anteriores, pero que mantiene una estructura conceptual similar.\nEl objetivo no es aprender una nueva t√©cnica, sino entender c√≥mo cambia el problema de predicci√≥n y c√≥mo ese cambio impacta en el comportamiento de la aplicaci√≥n.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 1 ‚Äì Un problema de predicci√≥n m√°s avanzado: detecci√≥n de objetos"
    ]
  },
  {
    "objectID": "sesion3/1_s3_parte_1.html#continuidad-con-lo-ya-visto",
    "href": "sesion3/1_s3_parte_1.html#continuidad-con-lo-ya-visto",
    "title": "bootcamp-dci",
    "section": "Continuidad con lo ya visto",
    "text": "Continuidad con lo ya visto\nEn la Sesi√≥n 2 se trabaj√≥ con funcionalidades de clasificaci√≥n de im√°genes, donde el sistema recibe una entrada (imagen o video) y produce una √∫nica etiqueta como resultado.\nDesde el punto de vista del software, ese tipo de funcionalidad responde a una pregunta simple del tipo:\n‚Äú¬øQu√© es esta imagen?‚Äù\nLa detecci√≥n de objetos mantiene la misma idea general de predicci√≥n, pero extiende el problema.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 1 ‚Äì Un problema de predicci√≥n m√°s avanzado: detecci√≥n de objetos"
    ]
  },
  {
    "objectID": "sesion3/1_s3_parte_1.html#ejemplo-del-caso-m√°s-avanzado",
    "href": "sesion3/1_s3_parte_1.html#ejemplo-del-caso-m√°s-avanzado",
    "title": "bootcamp-dci",
    "section": "Ejemplo del caso m√°s avanzado",
    "text": "Ejemplo del caso m√°s avanzado\nüëâ Ejemplo de detecci√≥n de objetos\nEste ejemplo muestra una funcionalidad que utiliza un modelo preentrenado para detectar m√∫ltiples objetos simult√°neamente en una imagen o en un flujo de video, marcando su posici√≥n aproximada en pantalla.\nEl comportamiento observable de la aplicaci√≥n permite analizar c√≥mo cambia la predicci√≥n cuando la salida del modelo deja de ser una etiqueta √∫nica.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 1 ‚Äì Un problema de predicci√≥n m√°s avanzado: detecci√≥n de objetos"
    ]
  },
  {
    "objectID": "sesion3/1_s3_parte_1.html#c√≥mo-cambia-el-problema-de-predicci√≥n",
    "href": "sesion3/1_s3_parte_1.html#c√≥mo-cambia-el-problema-de-predicci√≥n",
    "title": "bootcamp-dci",
    "section": "C√≥mo cambia el problema de predicci√≥n",
    "text": "C√≥mo cambia el problema de predicci√≥n\nEn una funcionalidad de detecci√≥n de objetos, el sistema ya no produce una sola predicci√≥n, sino m√∫ltiples predicciones simult√°neas.\nEl problema deja de ser identificar una imagen completa y pasa a ser:\n\nidentificar qu√© objetos aparecen,\ndeterminar cu√°ntos objetos hay,\ny estimar d√≥nde se encuentra cada uno dentro de la imagen o el video.\n\nEsto implica que la salida del modelo ya no es una etiqueta simple, sino un conjunto de resultados estructurados.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 1 ‚Äì Un problema de predicci√≥n m√°s avanzado: detecci√≥n de objetos"
    ]
  },
  {
    "objectID": "sesion3/1_s3_parte_1.html#tipo-de-entrada-y-tipo-de-salida",
    "href": "sesion3/1_s3_parte_1.html#tipo-de-entrada-y-tipo-de-salida",
    "title": "bootcamp-dci",
    "section": "Tipo de entrada y tipo de salida",
    "text": "Tipo de entrada y tipo de salida\nDesde el punto de vista de la aplicaci√≥n:\n\nla entrada puede ser una imagen fija o un flujo de video,\nla salida es una colecci√≥n de detecciones.\n\nCada detecci√≥n incluye informaci√≥n distinta a la vista en la clasificaci√≥n simple, como: - una etiqueta asociada al objeto, - y una ubicaci√≥n aproximada dentro del espacio visual.\nLa aplicaci√≥n debe interpretar esta informaci√≥n y decidir c√≥mo representarla en la interfaz.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 1 ‚Äì Un problema de predicci√≥n m√°s avanzado: detecci√≥n de objetos"
    ]
  },
  {
    "objectID": "sesion3/1_s3_parte_1.html#implicancias-para-el-dise√±o-del-software",
    "href": "sesion3/1_s3_parte_1.html#implicancias-para-el-dise√±o-del-software",
    "title": "bootcamp-dci",
    "section": "Implicancias para el dise√±o del software",
    "text": "Implicancias para el dise√±o del software\nEste cambio en el problema de predicci√≥n tiene consecuencias directas en el dise√±o de la funcionalidad:\n\nla interfaz ya no muestra un √∫nico resultado,\nel sistema debe manejar m√∫ltiples predicciones al mismo tiempo,\nel comportamiento del sistema es din√°mico y cambia continuamente,\ny la aplicaci√≥n debe actualizar su estado en funci√≥n de nuevas predicciones.\n\nEstas decisiones no dependen del modelo en s√≠, sino de c√≥mo la aplicaci√≥n utiliza las predicciones.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 1 ‚Äì Un problema de predicci√≥n m√°s avanzado: detecci√≥n de objetos"
    ]
  },
  {
    "objectID": "sesion3/1_s3_parte_1.html#en-qu√©-fijarse-durante-el-an√°lisis",
    "href": "sesion3/1_s3_parte_1.html#en-qu√©-fijarse-durante-el-an√°lisis",
    "title": "bootcamp-dci",
    "section": "En qu√© fijarse durante el an√°lisis",
    "text": "En qu√© fijarse durante el an√°lisis\nAl analizar este caso m√°s avanzado, el foco est√° en observar:\n\nc√≥mo se diferencia este problema de una clasificaci√≥n simple,\nqu√© tipo de informaci√≥n entrega el modelo,\nc√≥mo esa informaci√≥n es utilizada por la aplicaci√≥n,\ny qu√© nuevas decisiones de dise√±o aparecen.\n\nEl inter√©s est√° en comprender el problema de predicci√≥n, no en evaluar la calidad del modelo ni la precisi√≥n de las detecciones.\n\n\n\n\n\n\n\nNota\n\n\n\nEste caso sirve como marco de referencia para las demostraciones de la segunda parte de la sesi√≥n, mostrando que distintas funcionalidades de IA pueden compartir herramientas similares, pero resolver problemas de predicci√≥n distintos.",
    "crumbs": [
      "Sesi√≥n 3",
      "Parte 1 ‚Äì Un problema de predicci√≥n m√°s avanzado: detecci√≥n de objetos"
    ]
  },
  {
    "objectID": "association-rules/02_ejemplo_1.2.html",
    "href": "association-rules/02_ejemplo_1.2.html",
    "title": "Implementaci√≥n del ejemplo con python",
    "section": "",
    "text": "### Bibliotecas que necesitas Instalar:\n\n#! pip install mlxtend\n#! pip install pandas\n# Importar las bibliotecas necesarias\nimport pandas as pd\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori, association_rules\n\n# Datos de transacciones: lista de listas, donde cada sublista representa una transacci√≥n\ntransactions = [\n    ['Leche', 'Pan', 'Mantequilla'],\n    ['Leche', 'Pan'],\n    ['Leche', 'Manzana'],\n    ['Pan', 'Mantequilla'],\n    ['Leche', 'Pan', 'Mantequilla', 'Manzana'],\n    ['Manzana', 'Mantequilla']\n]\n\ntransactions\n\n[['Leche', 'Pan', 'Mantequilla'],\n ['Leche', 'Pan'],\n ['Leche', 'Manzana'],\n ['Pan', 'Mantequilla'],\n ['Leche', 'Pan', 'Mantequilla', 'Manzana'],\n ['Manzana', 'Mantequilla']]\n#Creamos una instancia de TransactionEncoder. \n# Este objeto se utiliza para transformar nuestras transacciones en una matriz booleana.\nte = TransactionEncoder()\nte\n\nTransactionEncoder()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.¬†TransactionEncoderiNot fittedTransactionEncoder()"
  },
  {
    "objectID": "association-rules/02_ejemplo_1.2.html#transactionencoder",
    "href": "association-rules/02_ejemplo_1.2.html#transactionencoder",
    "title": "Implementaci√≥n del ejemplo con python",
    "section": "TransactionEncoder",
    "text": "TransactionEncoder\nTransactionEncoder - es una clase de la biblioteca mlxtend que se utiliza para convertir listas de transacciones en una matriz booleana, - lo que es especialmente √∫til para el an√°lisis de asociaciones y la miner√≠a de datos.\n¬øQu√© es TransactionEncoder? - TransactionEncoder es un transformador que toma una lista de listas (donde cada sublista representa una transacci√≥n que contiene uno o m√°s √≠tems) - y la convierte en una matriz de formato booleano o de ceros y unos. - Cada fila de la matriz resultante representa una transacci√≥n, y cada columna representa un √≠tem. Los valores de la matriz indican la presencia (True o 1) o la ausencia (False o 0) de un √≠tem en cada transacci√≥n.\n¬øQu√© hace TransactionEncoder?\nAjuste y Transformaci√≥n:\nfit: Ajusta el codificador a los datos, identificando todos los √≠tems √∫nicos en el conjunto de transacciones. transform: Convierte las transacciones en una matriz booleana basada en los √≠tems identificados. fit_transform: Ajusta y transforma los datos en una sola operaci√≥n. Matriz Booleana: La matriz booleana generada tiene las siguientes caracter√≠sticas:\nFilas: Cada fila representa una transacci√≥n. Columnas: Cada columna representa un √≠tem √∫nico encontrado en las transacciones. Valores: True (o 1) indica que el √≠tem est√° presente en la transacci√≥n, y False (o 0) indica que el √≠tem no est√° presente.\n\n# Transformar los datos de transacciones en una matriz booleana\nte_ary = te.fit_transform(transactions)\nte_ary\n\narray([[ True,  True, False,  True],\n       [ True, False, False,  True],\n       [ True, False,  True, False],\n       [False,  True, False,  True],\n       [ True,  True,  True,  True],\n       [False,  True,  True, False]])\n\n\n\n# Convertir la matriz booleana en un DataFrame de pandas\n# te_ary: es la matriz booleana generada por TransactionEncoder, donde cada fila representa una transacci√≥n\n# y cada columna representa un producto. Un valor 1 indica que el producto est√° presente en la transacci√≥n,\n# y un valor 0 indica que no lo est√°.\n# columns=te.columns_: son los nombres de las columnas (los nombres de los productos) que se asignan a las columnas del DataFrame\ndf = pd.DataFrame(te_ary, columns=te.columns_)\n\n# Mostrar el DataFrame resultante para verificar la transformaci√≥n\ndf\n\n\n\n\n\n\n\n\nLeche\nMantequilla\nManzana\nPan\n\n\n\n\n0\nTrue\nTrue\nFalse\nTrue\n\n\n1\nTrue\nFalse\nFalse\nTrue\n\n\n2\nTrue\nFalse\nTrue\nFalse\n\n\n3\nFalse\nTrue\nFalse\nTrue\n\n\n4\nTrue\nTrue\nTrue\nTrue\n\n\n5\nFalse\nTrue\nTrue\nFalse\n\n\n\n\n\n\n\n\n# Calcular los √≠tems frecuentes utilizando el algoritmo Apriori\n# Utilizamos la funci√≥n apriori para encontrar √≠tems frecuentes en las transacciones\n# - df: El DataFrame que contiene las transacciones transformadas\n# - min_support=0.1: Definimos el soporte m√≠nimo como 0.1 (10%). Esto significa que un √≠tem debe aparecer en al menos el 10% de las transacciones para ser considerado frecuente.\n# - use_colnames=True: Usamos los nombres de las columnas (los nombres de los productos) en lugar de √≠ndices num√©ricos\nfrequent_itemsets = apriori(df, min_support=0.1, use_colnames=True)\n\n# Mostrar los √≠tems frecuentes y su soporte\nprint(\"√çtems frecuentes encontrados:\")\nfrequent_itemsets\n\n√çtems frecuentes encontrados:\n\n\n\n\n\n\n\n\n\nsupport\nitemsets\n\n\n\n\n0\n0.666667\n(Leche)\n\n\n1\n0.666667\n(Mantequilla)\n\n\n2\n0.500000\n(Manzana)\n\n\n3\n0.666667\n(Pan)\n\n\n4\n0.333333\n(Mantequilla, Leche)\n\n\n5\n0.333333\n(Manzana, Leche)\n\n\n6\n0.500000\n(Pan, Leche)\n\n\n7\n0.333333\n(Manzana, Mantequilla)\n\n\n8\n0.500000\n(Mantequilla, Pan)\n\n\n9\n0.166667\n(Manzana, Pan)\n\n\n10\n0.166667\n(Manzana, Mantequilla, Leche)\n\n\n11\n0.333333\n(Mantequilla, Pan, Leche)\n\n\n12\n0.166667\n(Manzana, Pan, Leche)\n\n\n13\n0.166667\n(Manzana, Mantequilla, Pan)\n\n\n14\n0.166667\n(Manzana, Mantequilla, Pan, Leche)\n\n\n\n\n\n\n\n\n# Generar las reglas de asociaci√≥n\n# Utilizamos la funci√≥n association_rules para generar las reglas a partir de los √≠tems frecuentes.\n# - frequent_itemsets: contiene los √≠tems frecuentes calculados con el algoritmo Apriori.\n# - metric: definimos la m√©trica \"confidence\" para evaluar las reglas.\n# - min_threshold: establecemos un umbral m√≠nimo de 0.5 (50%) para la m√©trica de confianza.\nrules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n\n# Filtrar y mostrar las reglas\n# Seleccionamos las columnas m√°s relevantes para mostrar: antecedentes, consecuentes, soporte, confianza y lift.\nrules = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\nprint(\"Reglas de asociaci√≥n generadas:\")\nrules\n\nReglas de asociaci√≥n generadas:\n\n\n\n\n\n\n\n\n\nantecedents\nconsequents\nsupport\nconfidence\nlift\n\n\n\n\n0\n(Mantequilla)\n(Leche)\n0.333333\n0.500000\n0.750\n\n\n1\n(Leche)\n(Mantequilla)\n0.333333\n0.500000\n0.750\n\n\n2\n(Manzana)\n(Leche)\n0.333333\n0.666667\n1.000\n\n\n3\n(Leche)\n(Manzana)\n0.333333\n0.500000\n1.000\n\n\n4\n(Pan)\n(Leche)\n0.500000\n0.750000\n1.125\n\n\n5\n(Leche)\n(Pan)\n0.500000\n0.750000\n1.125\n\n\n6\n(Manzana)\n(Mantequilla)\n0.333333\n0.666667\n1.000\n\n\n7\n(Mantequilla)\n(Manzana)\n0.333333\n0.500000\n1.000\n\n\n8\n(Mantequilla)\n(Pan)\n0.500000\n0.750000\n1.125\n\n\n9\n(Pan)\n(Mantequilla)\n0.500000\n0.750000\n1.125\n\n\n10\n(Manzana, Mantequilla)\n(Leche)\n0.166667\n0.500000\n0.750\n\n\n11\n(Manzana, Leche)\n(Mantequilla)\n0.166667\n0.500000\n0.750\n\n\n12\n(Mantequilla, Leche)\n(Manzana)\n0.166667\n0.500000\n1.000\n\n\n13\n(Mantequilla, Pan)\n(Leche)\n0.333333\n0.666667\n1.000\n\n\n14\n(Mantequilla, Leche)\n(Pan)\n0.333333\n1.000000\n1.500\n\n\n15\n(Pan, Leche)\n(Mantequilla)\n0.333333\n0.666667\n1.000\n\n\n16\n(Mantequilla)\n(Pan, Leche)\n0.333333\n0.500000\n1.000\n\n\n17\n(Pan)\n(Mantequilla, Leche)\n0.333333\n0.500000\n1.500\n\n\n18\n(Leche)\n(Mantequilla, Pan)\n0.333333\n0.500000\n1.000\n\n\n19\n(Manzana, Pan)\n(Leche)\n0.166667\n1.000000\n1.500\n\n\n20\n(Manzana, Leche)\n(Pan)\n0.166667\n0.500000\n0.750\n\n\n21\n(Manzana, Mantequilla)\n(Pan)\n0.166667\n0.500000\n0.750\n\n\n22\n(Manzana, Pan)\n(Mantequilla)\n0.166667\n1.000000\n1.500\n\n\n23\n(Manzana, Mantequilla, Pan)\n(Leche)\n0.166667\n1.000000\n1.500\n\n\n24\n(Manzana, Mantequilla, Leche)\n(Pan)\n0.166667\n1.000000\n1.500\n\n\n25\n(Manzana, Pan, Leche)\n(Mantequilla)\n0.166667\n1.000000\n1.500\n\n\n26\n(Mantequilla, Pan, Leche)\n(Manzana)\n0.166667\n0.500000\n1.000\n\n\n27\n(Manzana, Mantequilla)\n(Pan, Leche)\n0.166667\n0.500000\n1.000\n\n\n28\n(Manzana, Pan)\n(Mantequilla, Leche)\n0.166667\n1.000000\n3.000\n\n\n29\n(Manzana, Leche)\n(Mantequilla, Pan)\n0.166667\n0.500000\n1.000\n\n\n30\n(Mantequilla, Leche)\n(Manzana, Pan)\n0.166667\n0.500000\n3.000\n\n\n\n\n\n\n\n\n# Filtrar y mostrar las reglas\n# Seleccionamos solo las columnas relevantes para mostrar\nrules = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\nprint(\"Reglas de asociaci√≥n generadas:\")\nrules\n\nReglas de asociaci√≥n generadas:\n\n\n\n\n\n\n\n\n\nantecedents\nconsequents\nsupport\nconfidence\nlift\n\n\n\n\n0\n(Mantequilla)\n(Leche)\n0.333333\n0.500000\n0.750\n\n\n1\n(Leche)\n(Mantequilla)\n0.333333\n0.500000\n0.750\n\n\n2\n(Manzana)\n(Leche)\n0.333333\n0.666667\n1.000\n\n\n3\n(Leche)\n(Manzana)\n0.333333\n0.500000\n1.000\n\n\n4\n(Pan)\n(Leche)\n0.500000\n0.750000\n1.125\n\n\n5\n(Leche)\n(Pan)\n0.500000\n0.750000\n1.125\n\n\n6\n(Manzana)\n(Mantequilla)\n0.333333\n0.666667\n1.000\n\n\n7\n(Mantequilla)\n(Manzana)\n0.333333\n0.500000\n1.000\n\n\n8\n(Mantequilla)\n(Pan)\n0.500000\n0.750000\n1.125\n\n\n9\n(Pan)\n(Mantequilla)\n0.500000\n0.750000\n1.125\n\n\n10\n(Manzana, Mantequilla)\n(Leche)\n0.166667\n0.500000\n0.750\n\n\n11\n(Manzana, Leche)\n(Mantequilla)\n0.166667\n0.500000\n0.750\n\n\n12\n(Mantequilla, Leche)\n(Manzana)\n0.166667\n0.500000\n1.000\n\n\n13\n(Mantequilla, Pan)\n(Leche)\n0.333333\n0.666667\n1.000\n\n\n14\n(Mantequilla, Leche)\n(Pan)\n0.333333\n1.000000\n1.500\n\n\n15\n(Pan, Leche)\n(Mantequilla)\n0.333333\n0.666667\n1.000\n\n\n16\n(Mantequilla)\n(Pan, Leche)\n0.333333\n0.500000\n1.000\n\n\n17\n(Pan)\n(Mantequilla, Leche)\n0.333333\n0.500000\n1.500\n\n\n18\n(Leche)\n(Mantequilla, Pan)\n0.333333\n0.500000\n1.000\n\n\n19\n(Manzana, Pan)\n(Leche)\n0.166667\n1.000000\n1.500\n\n\n20\n(Manzana, Leche)\n(Pan)\n0.166667\n0.500000\n0.750\n\n\n21\n(Manzana, Mantequilla)\n(Pan)\n0.166667\n0.500000\n0.750\n\n\n22\n(Manzana, Pan)\n(Mantequilla)\n0.166667\n1.000000\n1.500\n\n\n23\n(Manzana, Mantequilla, Pan)\n(Leche)\n0.166667\n1.000000\n1.500\n\n\n24\n(Manzana, Mantequilla, Leche)\n(Pan)\n0.166667\n1.000000\n1.500\n\n\n25\n(Manzana, Pan, Leche)\n(Mantequilla)\n0.166667\n1.000000\n1.500\n\n\n26\n(Mantequilla, Pan, Leche)\n(Manzana)\n0.166667\n0.500000\n1.000\n\n\n27\n(Manzana, Mantequilla)\n(Pan, Leche)\n0.166667\n0.500000\n1.000\n\n\n28\n(Manzana, Pan)\n(Mantequilla, Leche)\n0.166667\n1.000000\n3.000\n\n\n29\n(Manzana, Leche)\n(Mantequilla, Pan)\n0.166667\n0.500000\n1.000\n\n\n30\n(Mantequilla, Leche)\n(Manzana, Pan)\n0.166667\n0.500000\n3.000\n\n\n\n\n\n\n\n\n# Interpretaci√≥n del resultado\n# Iterar sobre cada regla para imprimir una interpretaci√≥n m√°s clara\nfor idx, rule in rules.iterrows():\n    # Convertir los conjuntos de antecedentes y consecuentes en cadenas de texto\n    antecedents = ', '.join(list(rule['antecedents']))\n    consequents = ', '.join(list(rule['consequents']))\n    support = rule['support']\n    confidence = rule['confidence']\n    lift = rule['lift']\n    \n    # Imprimir la interpretaci√≥n de cada regla\n    print(f\"Regla: {antecedents} -&gt; {consequents}\")\n    print(f\"  Soporte: {support:.2f}\")\n    print(f\"  Confianza: {confidence:.2f}\")\n    print(f\"  Lift: {lift:.2f}\")\n    print(f\"  Interpretaci√≥n: Si un cliente compra {antecedents}, hay una confianza del {confidence:.2%} de que tambi√©n comprar√° {consequents}. El lift de {lift:.2f} indica que esta relaci√≥n es {lift:.2f} veces m√°s probable que si los productos fueran independientes.\\n\")\n\nRegla: Mantequilla -&gt; Leche\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 0.75\n  Interpretaci√≥n: Si un cliente compra Mantequilla, hay una confianza del 50.00% de que tambi√©n comprar√° Leche. El lift de 0.75 indica que esta relaci√≥n es 0.75 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Leche -&gt; Mantequilla\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 0.75\n  Interpretaci√≥n: Si un cliente compra Leche, hay una confianza del 50.00% de que tambi√©n comprar√° Mantequilla. El lift de 0.75 indica que esta relaci√≥n es 0.75 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana -&gt; Leche\n  Soporte: 0.33\n  Confianza: 0.67\n  Lift: 1.00\n  Interpretaci√≥n: Si un cliente compra Manzana, hay una confianza del 66.67% de que tambi√©n comprar√° Leche. El lift de 1.00 indica que esta relaci√≥n es 1.00 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Leche -&gt; Manzana\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretaci√≥n: Si un cliente compra Leche, hay una confianza del 50.00% de que tambi√©n comprar√° Manzana. El lift de 1.00 indica que esta relaci√≥n es 1.00 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Pan -&gt; Leche\n  Soporte: 0.50\n  Confianza: 0.75\n  Lift: 1.12\n  Interpretaci√≥n: Si un cliente compra Pan, hay una confianza del 75.00% de que tambi√©n comprar√° Leche. El lift de 1.12 indica que esta relaci√≥n es 1.12 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Leche -&gt; Pan\n  Soporte: 0.50\n  Confianza: 0.75\n  Lift: 1.12\n  Interpretaci√≥n: Si un cliente compra Leche, hay una confianza del 75.00% de que tambi√©n comprar√° Pan. El lift de 1.12 indica que esta relaci√≥n es 1.12 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana -&gt; Mantequilla\n  Soporte: 0.33\n  Confianza: 0.67\n  Lift: 1.00\n  Interpretaci√≥n: Si un cliente compra Manzana, hay una confianza del 66.67% de que tambi√©n comprar√° Mantequilla. El lift de 1.00 indica que esta relaci√≥n es 1.00 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Mantequilla -&gt; Manzana\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretaci√≥n: Si un cliente compra Mantequilla, hay una confianza del 50.00% de que tambi√©n comprar√° Manzana. El lift de 1.00 indica que esta relaci√≥n es 1.00 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Mantequilla -&gt; Pan\n  Soporte: 0.50\n  Confianza: 0.75\n  Lift: 1.12\n  Interpretaci√≥n: Si un cliente compra Mantequilla, hay una confianza del 75.00% de que tambi√©n comprar√° Pan. El lift de 1.12 indica que esta relaci√≥n es 1.12 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Pan -&gt; Mantequilla\n  Soporte: 0.50\n  Confianza: 0.75\n  Lift: 1.12\n  Interpretaci√≥n: Si un cliente compra Pan, hay una confianza del 75.00% de que tambi√©n comprar√° Mantequilla. El lift de 1.12 indica que esta relaci√≥n es 1.12 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana, Mantequilla -&gt; Leche\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 0.75\n  Interpretaci√≥n: Si un cliente compra Manzana, Mantequilla, hay una confianza del 50.00% de que tambi√©n comprar√° Leche. El lift de 0.75 indica que esta relaci√≥n es 0.75 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana, Leche -&gt; Mantequilla\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 0.75\n  Interpretaci√≥n: Si un cliente compra Manzana, Leche, hay una confianza del 50.00% de que tambi√©n comprar√° Mantequilla. El lift de 0.75 indica que esta relaci√≥n es 0.75 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Mantequilla, Leche -&gt; Manzana\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretaci√≥n: Si un cliente compra Mantequilla, Leche, hay una confianza del 50.00% de que tambi√©n comprar√° Manzana. El lift de 1.00 indica que esta relaci√≥n es 1.00 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Mantequilla, Pan -&gt; Leche\n  Soporte: 0.33\n  Confianza: 0.67\n  Lift: 1.00\n  Interpretaci√≥n: Si un cliente compra Mantequilla, Pan, hay una confianza del 66.67% de que tambi√©n comprar√° Leche. El lift de 1.00 indica que esta relaci√≥n es 1.00 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Mantequilla, Leche -&gt; Pan\n  Soporte: 0.33\n  Confianza: 1.00\n  Lift: 1.50\n  Interpretaci√≥n: Si un cliente compra Mantequilla, Leche, hay una confianza del 100.00% de que tambi√©n comprar√° Pan. El lift de 1.50 indica que esta relaci√≥n es 1.50 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Pan, Leche -&gt; Mantequilla\n  Soporte: 0.33\n  Confianza: 0.67\n  Lift: 1.00\n  Interpretaci√≥n: Si un cliente compra Pan, Leche, hay una confianza del 66.67% de que tambi√©n comprar√° Mantequilla. El lift de 1.00 indica que esta relaci√≥n es 1.00 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Mantequilla -&gt; Pan, Leche\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretaci√≥n: Si un cliente compra Mantequilla, hay una confianza del 50.00% de que tambi√©n comprar√° Pan, Leche. El lift de 1.00 indica que esta relaci√≥n es 1.00 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Pan -&gt; Mantequilla, Leche\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 1.50\n  Interpretaci√≥n: Si un cliente compra Pan, hay una confianza del 50.00% de que tambi√©n comprar√° Mantequilla, Leche. El lift de 1.50 indica que esta relaci√≥n es 1.50 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Leche -&gt; Mantequilla, Pan\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretaci√≥n: Si un cliente compra Leche, hay una confianza del 50.00% de que tambi√©n comprar√° Mantequilla, Pan. El lift de 1.00 indica que esta relaci√≥n es 1.00 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana, Pan -&gt; Leche\n  Soporte: 0.17\n  Confianza: 1.00\n  Lift: 1.50\n  Interpretaci√≥n: Si un cliente compra Manzana, Pan, hay una confianza del 100.00% de que tambi√©n comprar√° Leche. El lift de 1.50 indica que esta relaci√≥n es 1.50 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana, Leche -&gt; Pan\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 0.75\n  Interpretaci√≥n: Si un cliente compra Manzana, Leche, hay una confianza del 50.00% de que tambi√©n comprar√° Pan. El lift de 0.75 indica que esta relaci√≥n es 0.75 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana, Mantequilla -&gt; Pan\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 0.75\n  Interpretaci√≥n: Si un cliente compra Manzana, Mantequilla, hay una confianza del 50.00% de que tambi√©n comprar√° Pan. El lift de 0.75 indica que esta relaci√≥n es 0.75 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana, Pan -&gt; Mantequilla\n  Soporte: 0.17\n  Confianza: 1.00\n  Lift: 1.50\n  Interpretaci√≥n: Si un cliente compra Manzana, Pan, hay una confianza del 100.00% de que tambi√©n comprar√° Mantequilla. El lift de 1.50 indica que esta relaci√≥n es 1.50 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana, Mantequilla, Pan -&gt; Leche\n  Soporte: 0.17\n  Confianza: 1.00\n  Lift: 1.50\n  Interpretaci√≥n: Si un cliente compra Manzana, Mantequilla, Pan, hay una confianza del 100.00% de que tambi√©n comprar√° Leche. El lift de 1.50 indica que esta relaci√≥n es 1.50 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana, Mantequilla, Leche -&gt; Pan\n  Soporte: 0.17\n  Confianza: 1.00\n  Lift: 1.50\n  Interpretaci√≥n: Si un cliente compra Manzana, Mantequilla, Leche, hay una confianza del 100.00% de que tambi√©n comprar√° Pan. El lift de 1.50 indica que esta relaci√≥n es 1.50 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana, Pan, Leche -&gt; Mantequilla\n  Soporte: 0.17\n  Confianza: 1.00\n  Lift: 1.50\n  Interpretaci√≥n: Si un cliente compra Manzana, Pan, Leche, hay una confianza del 100.00% de que tambi√©n comprar√° Mantequilla. El lift de 1.50 indica que esta relaci√≥n es 1.50 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Mantequilla, Pan, Leche -&gt; Manzana\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretaci√≥n: Si un cliente compra Mantequilla, Pan, Leche, hay una confianza del 50.00% de que tambi√©n comprar√° Manzana. El lift de 1.00 indica que esta relaci√≥n es 1.00 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana, Mantequilla -&gt; Pan, Leche\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretaci√≥n: Si un cliente compra Manzana, Mantequilla, hay una confianza del 50.00% de que tambi√©n comprar√° Pan, Leche. El lift de 1.00 indica que esta relaci√≥n es 1.00 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana, Pan -&gt; Mantequilla, Leche\n  Soporte: 0.17\n  Confianza: 1.00\n  Lift: 3.00\n  Interpretaci√≥n: Si un cliente compra Manzana, Pan, hay una confianza del 100.00% de que tambi√©n comprar√° Mantequilla, Leche. El lift de 3.00 indica que esta relaci√≥n es 3.00 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Manzana, Leche -&gt; Mantequilla, Pan\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretaci√≥n: Si un cliente compra Manzana, Leche, hay una confianza del 50.00% de que tambi√©n comprar√° Mantequilla, Pan. El lift de 1.00 indica que esta relaci√≥n es 1.00 veces m√°s probable que si los productos fueran independientes.\n\nRegla: Mantequilla, Leche -&gt; Manzana, Pan\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 3.00\n  Interpretaci√≥n: Si un cliente compra Mantequilla, Leche, hay una confianza del 50.00% de que tambi√©n comprar√° Manzana, Pan. El lift de 3.00 indica que esta relaci√≥n es 3.00 veces m√°s probable que si los productos fueran independientes."
  },
  {
    "objectID": "association-rules/03_ejercicio.html",
    "href": "association-rules/03_ejercicio.html",
    "title": "Determine las reglas de asociaci√≥n para el siguiente conjunto de transacciones",
    "section": "",
    "text": "['Leche', 'Pan', 'Mantequilla']\n['Leche', 'Pan']\n['Leche', 'Manzana']\n['Pan', 'Mantequilla']\n['Leche', 'Pan', 'Mantequilla', 'Manzana']\n['Manzana', 'Mantequilla']\n['Leche', 'Manzana', 'Cereal']\n['Pan', 'Cereal']\n['Leche', 'Pan', 'Cereal']\n['Mantequilla', 'Manzana', 'Cereal']\n['Leche', 'Cereal', 'Galletas']\n['Pan', 'Galletas']\n['Leche', 'Pan', 'Galletas']\n['Manzana', 'Galletas']\n['Leche', 'Manzana', 'Galletas']\n['Pan', 'Mantequilla', 'Cereal']\n['Leche', 'Mantequilla', 'Cereal']\n['Leche', 'Pan', 'Manzana', 'Galletas']\n['Manzana', 'Mantequilla', 'Galletas']\n['Leche', 'Cereal', 'Manzana', 'Galletas']"
  }
]